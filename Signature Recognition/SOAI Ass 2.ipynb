{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SOAI Ass 2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ua2zf9fTETvq","colab_type":"code","colab":{}},"source":["##1\n","import cv2\n","import tensorflow.keras as keras\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import random\n","\n","shape = (125, 50)\n","#50, 125"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"42Kdfc2pU3iF","colab_type":"code","colab":{}},"source":["persons = []\n","real_dir = '/content/drive/My Drive/SOAI/Ass 2 /dataset2/real'\n","fake_dir= '/content/drive/My Drive/SOAI/Ass 2 /dataset2/forge'\n","\n","w =[]\n","h =[]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NECRJQP2ww5-","colab_type":"text"},"source":["###Storing and Resizing the Images in corresponding variables. Different variables have the following meanings:\n","real001  -->> list of Image of real signatures of person 001\n","\n","\n","real002  -->> list of Image of real signatures of person 002\n","\n","\n",".\n","\n","\n",".\n","\n","\n",".\n","\n","\n","real005  -->> list of Image of real signatures of person 005\n","\n","Fake001  -->> list of Image of fake signatures of person 001\n","\n","\n","'\n","\n","\n","'\n","\n","\n","'\n","\n","\n","'\n","\n","\n","fake005   -->> list of Image of fake signatures of person 005\n","\n","\n","Data has been downloaded from the following Kaggle Dataset into my Gdrive - https://www.kaggle.com/divyanshrai/handwritten-signatures\n","\n","I chose this data because I could not find any free publicly available Dataset forthe same. \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"h_XoF1O7YucW","colab_type":"text"},"source":["## 001"]},{"cell_type":"code","metadata":{"id":"NPxvuLFOFMe8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1592825436634,"user_tz":-330,"elapsed":1518,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"b6c8b671-e41c-4663-833c-8a0667791646"},"source":["ls = os.listdir(real_dir)\n","real001 = []\n","for i in range(len(ls)):\n","  # list \n","  if ls[i][0:3] in persons:\n","    pass\n","  else:\n","    persons.append(ls[i][0:3])\n","  #list\n","  if(ls[i][0:3] == '001'):\n","    real001.append(cv2.resize(cv2.imread(real_dir+'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n","len(persons)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"nWNySnMpQGJq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"executionInfo":{"status":"ok","timestamp":1592825441114,"user_tz":-330,"elapsed":2098,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"0d737599-bee7-4010-b5bb-d3853be10ca1"},"source":["#+32, 61, 88\n","ls = os.listdir(fake_dir)\n","fake001 = []\n","for i in range(len(ls)):\n","  # list \n","  if ls[i][0:3] in persons:\n","    pass\n","  else:\n","    persons.append(ls[i][0:3])\n","  #list\n","  if(ls[i].find('001', 3) != -1):\n","    fake001.append(cv2.resize(cv2.imread(fake_dir + '/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","persons.sort()\n","persons\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['001',\n"," '002',\n"," '003',\n"," '004',\n"," '005',\n"," '006',\n"," '007',\n"," '008',\n"," '009',\n"," '010',\n"," '011',\n"," '012',\n"," '021',\n"," '022']"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"aI7coVQoY5fD","colab_type":"text"},"source":["##002"]},{"cell_type":"code","metadata":{"id":"4Bg_H4FIY7BI","colab_type":"code","colab":{}},"source":["ls = os.listdir(real_dir)\n","real002 = []\n","for i in range(len(ls)):\n","  if(ls[i][0:3] == '002'):\n","    real002.append(cv2.resize(cv2.imread(real_dir+'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n","\n","ls = os.listdir(fake_dir)\n","fake002 = []\n","for i in range(len(ls)):\n","  if(ls[i].find('002', 3) != -1):\n","    fake002.append(cv2.resize(cv2.imread(fake_dir +'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GgXganmlZsR6","colab_type":"text"},"source":["## 003"]},{"cell_type":"code","metadata":{"id":"l5qLEcVPZrPh","colab_type":"code","colab":{}},"source":["ls = os.listdir(real_dir)\n","real003 = []\n","for i in range(len(ls)):\n","  if(ls[i][0:3] == '003'):\n","    real003.append(cv2.resize(cv2.imread(real_dir +'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n","\n","ls = os.listdir(fake_dir)\n","fake003 = []\n","for i in range(len(ls)):\n","  if(ls[i].find('003', 3) != -1):\n","    fake003.append(cv2.resize(cv2.imread(fake_dir +'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-6sxmSfZ-Aj","colab_type":"text"},"source":["#004"]},{"cell_type":"code","metadata":{"id":"cemQ1prDaAOK","colab_type":"code","colab":{}},"source":["ls = os.listdir(real_dir)\n","real004 = []\n","for i in range(len(ls)):\n","  if(ls[i][0:3] == '004'):\n","    real004.append(cv2.resize(cv2.imread(real_dir+'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n","\n","ls = os.listdir(fake_dir)\n","fake004 = []\n","for i in range(len(ls)):\n","  if(ls[i].find('004', 3) != -1):\n","    fake004.append(cv2.resize(cv2.imread(fake_dir +'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZLJO2M-yaVxU","colab_type":"text"},"source":["##005"]},{"cell_type":"code","metadata":{"id":"nOLXZh1xaXfF","colab_type":"code","colab":{}},"source":["ls = os.listdir(real_dir)\n","real005 = []\n","for i in range(len(ls)):\n","  if(ls[i][0:3] == '005'):\n","    real005.append(cv2.resize(cv2.imread(real_dir +'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n","\n","ls = os.listdir(fake_dir)\n","fake005 = []\n","for i in range(len(ls)):\n","  if(ls[i].find('005', 3) != -1):\n","    fake005.append(cv2.resize(cv2.imread(fake_dir +'/'+ls[i]), shape, interpolation = cv2.INTER_AREA))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wldmymGFqQm4","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EaelPJ7fzThz","colab_type":"text"},"source":["#METRIC LEARNING APPROACH\n","\n","\n","Here we are going to use the Architecture used for Face Recognition model. The Network will take a set of three images (real signature of a person, another real signature of same person, fake signature of that person), and output three encoded vectors of length 500 each, encoding the features of each image. \n","\n","The good thing about the mode is that it is not writer specific, i.e., once it is trained it can differentiate between real and fake signatures of any other person who might not be in the training set. \n","\n","on the other hand, the downside of the model is that it requires fake signatures of persons for training, which are less practical way of approaching the problem.\n"]},{"cell_type":"markdown","metadata":{"id":"jYRQ9QT0bmcx","colab_type":"text"},"source":["### DATA PREPARATION\n","\n","So, the input data is created as sets of three images in the manner described above."]},{"cell_type":"code","metadata":{"id":"BT_tQnQQblVa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1592822403027,"user_tz":-330,"elapsed":17079,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"19960e7e-e1ec-4d1c-c01b-c647d7a157b0"},"source":["set1 = []\n","set2 = []\n","set3 = []\n","Y = []\n","\n","for real, fake in zip([real001, real002, real003,real004, real005], [fake001, fake002, fake003, fake004, fake005]):\n","  for i in range(20):\n","    r = np.random.randint(0, high=len(real), size=2)\n","    set1.append(real[r[0]])\n","    set2.append(real[r[1]])\n","    r = np.random.randint(0, high=len(fake), size=1)\n","    set3.append(fake[r[0]])\n","\n","set1 = np.asarray(set1)\n","set2 = np.asarray(set2)\n","set3 = np.asarray(set3)\n","#set1 = set1/255 - 0.5\n","#set2 = set2/255 - 0.5\n","Y = np.zeros((set1.shape[0], 500,3))\n","print(set1.shape, set2.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(100, 50, 125, 3) (100, 50, 125, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uz8xBHQH13Yw","colab_type":"text"},"source":["###ARCHITECTURE\n","\n","The model consists of two parts namely, encoder and comparator\n","\n","ENCODER : takes three images, runns CNN over all of them and finally outputs three 500 dimensional vector for each image, encoding the image features. Loss function aims to reduce the gap between outputs of real signatures pair , and widen the gap between vectors of real and fake image pair.\n","It is trained on the data generated above.\n","\n","COMPARATOR : This takes two images, one of real signature, and other of the signature which is to be tested against it. Thiese images arre passed through the encoder above, and their freatures are extracted. These are then passed through another neural network of densely connected layers which outputs a number between 0 and 1 signifying closeness. i.e. the more close to 0, the more is the second signature is matching to the real one. \n","\n","This is trained by keeping the encoder weights fixed and training the densely connected neural- network ahead of it. \n","\n","._. I tried to train the whole network at once, but it did not work out well. The reason might be that the weights of the ENCODER, which are trained using Approach for Face Recognition, are trained to differentiate between the images. But training them from comparatoe point of view, might force it to leave this behaviour and assume some other behaviour which is not able to differentiate between very similar images(as all fake signatures are). "]},{"cell_type":"markdown","metadata":{"id":"Gs2tIJvlbF79","colab_type":"text"},"source":["### Siamese Network Model for feature Encoding (ENCODER MODEL CREATION AND TRAINING)\n","\n","We use pretraines VGG 16 model for creating a part of the encoder.\n"]},{"cell_type":"code","metadata":{"id":"7cM6kzNKkuQS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1592822411770,"user_tz":-330,"elapsed":24623,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"eff80978-2723-4648-aa2c-f7250753e8cf"},"source":["premodel = keras.applications.VGG16(include_top=False,weights=\"imagenet\", input_shape=(50,125,3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ghFjPb1GpuN3","colab_type":"code","colab":{}},"source":["def added_model():\n","  inp = keras.layers.Input(1536)\n","  D = keras.layers.Dense(500)(inp)\n","  return keras.Model(inp, D)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"64_S6QBIDbx5","colab_type":"code","colab":{}},"source":["added_model = added_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVx34KY4cOM6","colab_type":"code","colab":{}},"source":["def model():\n","  inp1 = keras.layers.Input(shape=(50,125,3))\n","  inp2 = keras.layers.Input(shape=(50,125,3))\n","  inp3 = keras.layers.Input(shape=(50,125,3))\n","\n","  out1 = premodel(inp1)\n","  out1 = keras.layers.Flatten()(out1)\n","  out1 = added_model(out1)\n","\n","  out2 = premodel(inp2)\n","  out2 = keras.layers.Flatten()(out2)\n","  out2 = added_model(out2)\n","  \n","  out3 = premodel(inp3)\n","  out3 = keras.layers.Flatten()(out3)\n","  out3 = added_model(out3)\n","\n","  out = keras.layers.Lambda(lambda x: tf.concat(x, axis = 2))([tf.expand_dims(out1, -1), tf.expand_dims(out2, -1), tf.expand_dims(out3, -1)])\n","  model = keras.Model([inp1, inp2, inp3], out)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCRTZB4Me5tj","colab_type":"code","colab":{}},"source":["encoder = model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flCPtEvGfBLl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":652},"executionInfo":{"status":"ok","timestamp":1592822412948,"user_tz":-330,"elapsed":23277,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"5a442768-4926-4af9-a08f-742ea25d398a"},"source":["encoder.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 50, 125, 3)] 0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 50, 125, 3)] 0                                            \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            [(None, 50, 125, 3)] 0                                            \n","__________________________________________________________________________________________________\n","vgg16 (Model)                   (None, 1, 3, 512)    14714688    input_3[0][0]                    \n","                                                                 input_4[0][0]                    \n","                                                                 input_5[0][0]                    \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 1536)         0           vgg16[1][0]                      \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 1536)         0           vgg16[2][0]                      \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 1536)         0           vgg16[3][0]                      \n","__________________________________________________________________________________________________\n","model (Model)                   (None, 500)          768500      flatten[0][0]                    \n","                                                                 flatten_1[0][0]                  \n","                                                                 flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","tf_op_layer_ExpandDims (TensorF [(None, 500, 1)]     0           model[1][0]                      \n","__________________________________________________________________________________________________\n","tf_op_layer_ExpandDims_1 (Tenso [(None, 500, 1)]     0           model[2][0]                      \n","__________________________________________________________________________________________________\n","tf_op_layer_ExpandDims_2 (Tenso [(None, 500, 1)]     0           model[3][0]                      \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 500, 3)       0           tf_op_layer_ExpandDims[0][0]     \n","                                                                 tf_op_layer_ExpandDims_1[0][0]   \n","                                                                 tf_op_layer_ExpandDims_2[0][0]   \n","==================================================================================================\n","Total params: 15,483,188\n","Trainable params: 15,483,188\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"quAhiY-TfFjW","colab_type":"code","colab":{}},"source":["def loss_fn(y_true, y_pred):\n","  loss_same = tf.reduce_mean(tf.math.square(tf.math.subtract(y_pred[:,:, 0] , y_pred[:,:,1])))\n","  loss_diff = -tf.reduce_mean(tf.math.square(tf.math.subtract(y_pred[:,:, 0] , y_pred[:,:,2])))\n","  loss = loss_diff + loss_same\n","  loss = 1/(1+tf.math.exp(-loss))\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7x9j88HGwHV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1592822439269,"user_tz":-330,"elapsed":26309,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"29ec956d-52aa-4e15-b2d3-8cdedd367b56"},"source":["\n","#encoder = keras.models.load_model('/content/drive/My Drive/SOAI/Ass 2 /encoder.hdf5', custom_objects={'loss_fn': loss_fn})\n","premodel = keras.models.load_model('/content/drive/My Drive/SOAI/Ass 2 /premodel.hdf5')\n","added_model = keras.models.load_model('/content/drive/My Drive/SOAI/Ass 2 /added_model.hdf5')\n","\n","#encoder = keras.Model(premodel.input, D1(premodel.output))\n","#m = keras.models.load_model('/content/drive/My Drive/SOAI/Ass 2 /m.hdf5', custom_objects={'loss_fn': loss_fn})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-j5BNh_AS5Xm","colab_type":"code","colab":{}},"source":["encoder = model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqGEtwW4i0_4","colab_type":"code","colab":{}},"source":["encoder.compile(loss = loss_fn, optimizer = 'Adam')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ztmNjTQjLmH","colab_type":"code","colab":{}},"source":["for i in range(1000):\n","  print(i)\n","  encoder.fit([set1, set2, set3], Y, batch_size=set1.shape[0], epochs = 10)\n","  encoder.save('/content/drive/My Drive/SOAI/Ass 2 /encoder.hdf5')\n","  premodel.save('/content/drive/My Drive/SOAI/Ass 2 /premodel.hdf5')\n","  added_model.save('/content/drive/My Drive/SOAI/Ass 2 /added_model.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"678OLKtjmdt7","colab_type":"text"},"source":["###Comparor"]},{"cell_type":"markdown","metadata":{"id":"-7J2xL2YmHOq","colab_type":"text"},"source":["### Data Preparation for Comparor"]},{"cell_type":"code","metadata":{"id":"8a-7WEtomC_c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1592822478222,"user_tz":-330,"elapsed":2122,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"361d2bbe-c9e8-4cca-8794-4e79e75285f6"},"source":["set1 = []\n","set2 = []\n","\n","Y = []\n","# real vs real\n","for real, fake in zip([real001, real002, real003,real004, real005], [fake001, fake002, fake003, fake004, fake005]):\n","  for i in range(15):\n","    r = np.random.randint(0, high=len(real), size=1)\n","    set1.append(real[r[0]])\n","    r = np.random.randint(0, high=len(fake), size=1)\n","    set2.append(fake[r[0]])\n","    r = np.random.randint(0, high=len(real), size=1)\n","    set1.append(real[r[0]])\n","    r = np.random.randint(0, high=len(fake), size=1)\n","    set2.append(real[r[0]])\n","    Y.append(-1)\n","    Y.append(1)\n","set1 = np.asarray(set1)\n","set2 = np.asarray(set2)\n","Y = np.asarray(Y)\n","Y_fake = np.zeros(()) \n","print(set1.shape, set2.shape, Y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(150, 50, 125, 3) (150, 50, 125, 3) (150,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VmVTgZFVoJav","colab_type":"code","colab":{}},"source":["##2\n","def loss_fnc(y_true, y_pred):\n","  return tf.reduce_sum(tf.multiply(y_pred,y_true))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E3cus3m3-wGW","colab_type":"code","colab":{}},"source":["premodel.trainable = False\n","added_model.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WE7ghdRgkp0r","colab_type":"code","colab":{}},"source":["def comparor():\n","  inp1 = keras.layers.Input(shape = (50,125, 3))\n","  inp2 = keras.layers.Input(shape = (50,125, 3))\n","  feature1 = premodel(inp1)\n","  feature1 = keras.layers.Flatten()(feature1)\n","  feature1 = added_model(feature1)\n","  feature2 = premodel(inp2)\n","  feature2 = keras.layers.Flatten()(feature2)\n","  feature2 = added_model(feature2)\n","\n","  concat = keras.layers.Lambda(lambda x : tf.concat(x, axis = -1))([feature1, feature2])\n","  out = keras.layers.Dense(100, activation = 'elu')(concat)\n","  out = keras.layers.Dense(50, activation = 'elu')(out)\n","  out = keras.layers.Dense(10, activation = 'elu')(out)\n","  closeness = keras.layers.Dense(1, activation = 'sigmoid')(out)\n","  #diff = keras.layers.Lambda(lambda x : tf.math.square(tf.math.subtract(x[0] , x[1])))([feature1, feature2])\n","  model = keras.Model([inp1, inp2], closeness)\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ViknTvjEl9tZ","colab_type":"code","colab":{}},"source":["comparor = comparor()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xro41OE9HER1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":569},"executionInfo":{"status":"ok","timestamp":1592817305302,"user_tz":-330,"elapsed":1128,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"c3a0ccde-4e2c-4ffb-d0df-02be603ad371"},"source":["comparor.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, 50, 125, 3)] 0                                            \n","__________________________________________________________________________________________________\n","input_7 (InputLayer)            [(None, 50, 125, 3)] 0                                            \n","__________________________________________________________________________________________________\n","vgg16 (Model)                   (None, 1, 3, 512)    14714688    input_6[0][0]                    \n","                                                                 input_7[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 1536)         0           vgg16[4][0]                      \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 1536)         0           vgg16[5][0]                      \n","__________________________________________________________________________________________________\n","model_1 (Model)                 (None, 500)          768500      flatten_3[0][0]                  \n","                                                                 flatten_4[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 1000)         0           model_1[4][0]                    \n","                                                                 model_1[5][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 100)          100100      lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 50)           5050        dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 10)           510         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1)            11          dense_3[0][0]                    \n","==================================================================================================\n","Total params: 15,588,859\n","Trainable params: 105,671\n","Non-trainable params: 15,483,188\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BfwxGFaopKR2","colab_type":"code","colab":{}},"source":["##4\n","comparor.compile(optimizer = 'Adam', loss = loss_fnc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8q3SW6RQT4pg","colab_type":"code","colab":{}},"source":["##3\n","comparor = keras.models.load_model('/content/drive/My Drive/SOAI/Ass 2 /comparor.hdf5', custom_objects={'loss_fnc':loss_fnc})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8CxjUzUmBkP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1592822545093,"user_tz":-330,"elapsed":14842,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"1475dd02-ba6b-4b2c-ae4f-3400ad5e92f9"},"source":["comparor.fit([set1, set2], Y, batch_size = set1.shape[0], epochs = 500)\n","comparor.save('/content/drive/My Drive/SOAI/Ass 2 /comparor.hdf5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4394ed9cd553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomparor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcomparor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/SOAI/Ass 2 /comparor.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    648\u001b[0m               *args, **kwds)\n\u001b[1;32m    649\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vAvi1BwS_Sul","colab_type":"code","colab":{}},"source":["correct = 0\n","incorrect = 0\n","for i in range(Y.shape[0]):\n","  pred = comparor.predict([set1[i:i+1], set2[i:i+1]])\n","  if pred[0,0] <=  0.5 :\n","    if Y[i] == 1:\n","      correct +=1\n","    else:\n","      incorrect +=1\n","  else :\n","    if Y[i] == -1:\n","      correct +=1\n","    else:\n","      incorrect +=1\n","print('Accuracy : ' , correct/(correct+incorrect))  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZSDzvq7n46y","colab_type":"text"},"source":["###Test Set Preparation"]},{"cell_type":"code","metadata":{"id":"UIKs9VmNSlXM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1592822650462,"user_tz":-330,"elapsed":1388,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"9e45fcff-b58a-4e58-c10c-a3e565b15303"},"source":["set1 = []\n","set2 = []\n","\n","Y = []\n","# real vs real\n","for real, fake in zip([real001, real002, real003,real004, real005], [fake001, fake002, fake003, fake004, fake005]):\n","  for i in range(5):\n","    r = np.random.randint(0, high=len(real), size=1)\n","    set1.append(real[r[0]])\n","    r = np.random.randint(0, high=len(fake), size=1)\n","    set2.append(fake[r[0]])\n","    r = np.random.randint(0, high=len(real), size=1)\n","    set1.append(real[r[0]])\n","    r = np.random.randint(0, high=len(fake), size=1)\n","    set2.append(real[r[0]])\n","    Y.append(-1)\n","    Y.append(1)\n","set1 = np.asarray(set1)\n","set2 = np.asarray(set2)\n","Y = np.asarray(Y)\n","Y_fake = np.zeros(()) \n","print(set1.shape, set2.shape, Y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(50, 50, 125, 3) (50, 50, 125, 3) (50,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iRF9y7WroPK4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592823096615,"user_tz":-330,"elapsed":4022,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"7021c871-0d73-4469-e62c-300e686bfc95"},"source":["correct = 0\n","incorrect = 0\n","for i in range(Y.shape[0]):\n","  pred = comparor.predict([set1[i:i+1], set2[i:i+1]])\n","  if pred[0,0] <=  0.5 :\n","    print('PREDICTED : real')\n","    if Y[i] == 1:\n","      correct +=1\n","    else:\n","      incorrect +=1\n","  else :\n","    print('PREDICTED : fake')\n","    if Y[i] == -1:\n","      correct +=1\n","    else:\n","      incorrect +=1\n","  if Y[i] == 1:\n","    print('ACTUAl : real')\n","  else:\n","    print('ACTUAL : fake')\n","print('Accuracy : ' , correct/(correct+incorrect))  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","PREDICTED : fake\n","ACTUAL : fake\n","PREDICTED : real\n","ACTUAl : real\n","Accuracy :  1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SjyUoiMkRhyX","colab_type":"code","colab":{}},"source":["##5\n","set1 = [ cv2.resize(cv2.imread('path to the real signature image of the person'), shape, interpolation = cv2.INTER_AREA)]\n","set1 = np.asarray(set1)\n","set2 = [cv2.resize(cv2.imread('path to the image to be tested'), shape, interpolation = cv2.INTER_AREA)]\n","set2 = np.asarray(set2)\n","\n","\n","pred = comparor.predict([set1, set2])\n","if pred[0,0] <=  0.5 :\n","  print('PREDICTED : real')\n","else:    \n","  print('PREDICTED : fake')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQqlSHYCWE21","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1593002554742,"user_tz":-330,"elapsed":2952,"user":{"displayName":"Himanshu verma","photoUrl":"","userId":"13220883568166298050"}},"outputId":"18bab5b1-40ae-45b5-d89b-cb0f9982bc58"},"source":["a = np.zeros((10))\n","print(a.shape)\n","a = [a]\n","a = np.asarray(a)\n","print(a.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(10,)\n","(1, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YCYV1WDy_-ya","colab_type":"text"},"source":["###NOTE : The model is showing 100 percent accuracy as it is trained on a very limited dataset(I was not able to find a bigger publicly available dataset). But the way in which it is trained ensures that it works fine for any other dataset probably with condition of black ink on white background(as all images in training data were in sam format).\n"]},{"cell_type":"markdown","metadata":{"id":"4B2nfYDs1WyN","colab_type":"text"},"source":[" # *FAILED ATTEMPTS*"]},{"cell_type":"markdown","metadata":{"id":"hjd-iwBfqRfa","colab_type":"text"},"source":["#CNN LSTM BASED APPROACH\n","was not able to differentiate between the real and fake signatures. The reason is not clear, Maybe the LSTM design does not capture the differentiating aspect of a signature."]},{"cell_type":"code","metadata":{"id":"fLJMKHKiwMG2","colab_type":"code","colab":{}},"source":["set1 = []\n","set2 = []\n","Y = []\n","# real vs real\n","for real, fake in zip([real001, real002, real003,real004, real005], [fake001, fake002, fake003, fake004, fake005]):\n","  for i in range(20):\n","    r = np.random.randint(0, high=len(real), size=2)\n","    set1.append(real[r[0]])\n","    set2.append(real[r[1]])\n","    Y.append([1,0])\n","    r1 = np.random.randint(0, high=len(real), size=1)\n","    r2 = np.random.randint(0, high=len(fake), size=1)\n","    if (i < 10):\n","      set1.append(real[r1[0]])\n","      set2.append(fake[r2[0]])\n","      Y.append([0,1])\n","    else:\n","      set1.append(fake[r2[0]])\n","      set2.append(real[r1[0]])\n","      Y.append([0,1])\n","\n","set1 = np.asarray(set1)\n","set2 = np.asarray(set2)\n","Y = np.asarray(Y)\n","#set1 = set1/255 - 0.5\n","#set2 = set2/255 - 0.5\n","print(set1.shape, set2.shape, Y.shape, Y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RPycjShwMKz","colab_type":"code","colab":{}},"source":["def encoder(height, width):\n","  inp1 = keras.Input(shape = (height, width,3))\n","  inp2 = keras.Input(shape = (height, width,3))\n","  l1 = keras.layers.Conv2D(32, (height, 5), activation = 'elu')\n","  l2 = keras.layers.Conv2D(64, (32, 5), activation = 'elu')\n","  l3 = keras.layers.Conv2D(128, (64, 5), activation = 'elu')\n","  l4 = keras.layers.Conv2D(256, (128, 5), activation = 'elu')\n","  l5 = keras.layers.Conv2D(512, (256, 5), activation = 'elu')\n","  bi1 = keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True), merge_mode=\"concat\")\n","\n","  en1 = l1(inp1)\n","  en1 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en1)\n","  en1 = keras.layers.AveragePooling1D(pool_size=2, strides=2, padding=\"valid\")(en1)\n","  # (none, steps/2, 32)\n","  en1 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en1)\n","  # (none, 32, steps/2,1)\n","  \n","  en1 = l2(en1)\n","  en1 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en1)\n","  #(none, steps/2, 64)\n","  #en1 = keras.layers.AveragePooling1D(pool_size=2, strides=2, padding=\"valid\")(en1)\n","\n","  en1 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en1)\n","  en1 = l3(en1)\n","  en1 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en1)\n","\n","  en1 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en1)\n","  en1 = l4(en1)\n","  en1 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en1)\n","\n","  en1 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en1)\n","  en1 = l5(en1)\n","  en1 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en1)\n","  \n","  en1 = bi1(en1)\n","\n","  en2 = l1(inp2)\n","  en2 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en2)\n","  en2 = keras.layers.AveragePooling1D(pool_size=2, strides=2, padding=\"valid\")(en2)\n","  # (none, steps/2, 32)\n","  en2 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en2)\n","  # (none, 32, steps/2,1)\n","  \n","  en2 = l2(en2)\n","  en2 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en2)\n","  #(none, steps/2, 64)\n","  #en1 = keras.layers.AveragePooling1D(pool_size=2, strides=2, padding=\"valid\")(en1)\n","\n","  en2 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en2)\n","  en2 = l3(en2)\n","  en2 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en2)\n","\n","  en2 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en2)\n","  en2 = l4(en2)\n","  en2 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en2)\n","\n","  en2 = keras.layers.Lambda(lambda x: tf.expand_dims(tf.transpose(x, [0,2,1]), -1))(en2)\n","  en2 = l5(en2)\n","  en2 = keras.layers.Lambda(lambda x:tf.squeeze(x, [-3]))(en2)\n","  \n","  en2 = bi1(en2)\n","\n","  model = keras.Model([inp1, inp2], [en1, en2])\n","  return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4bBHY6dwMNE","colab_type":"code","colab":{}},"source":["enc = encoder(shape[1], shape[0])\n","enc.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PT83jUNvwMQQ","colab_type":"code","colab":{}},"source":["def discriminator():\n","  inp1 = keras.Input(shape = enc.layers[-1].output_shape[1:])\n","  inp2 = keras.Input(shape = enc.layers[-1].output_shape[1:])\n","  con = keras.layers.Lambda(lambda x: tf.concat(x, axis = 2))([inp1, inp2])\n","  lstm = keras.layers.Bidirectional(keras.layers.LSTM(50, return_sequences=True), merge_mode = 'concat')(con)\n","  lstm = keras.layers.Bidirectional(keras.layers.LSTM(25, return_sequences=True), merge_mode = 'concat')(lstm)\n","  lstm = keras.layers.Bidirectional(keras.layers.LSTM(10, return_sequences=True), merge_mode = 'concat')(lstm)\n","  fl = keras.layers.Flatten()(lstm)\n","  out = keras.layers.Dense(1000, activation = 'elu')(fl)\n","  out = keras.layers.Dense(100,activation = 'elu')(out)\n","  out = keras.layers.Dense(10, activation = 'elu')(out)\n","  out = keras.layers.Dense(2, activation = 'softmax')(out)\n","  return keras.Model([inp1, inp2], out)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEN9AcoFwME_","colab_type":"code","colab":{}},"source":["dis = discriminator()\n","dis.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"klPKfqZcitxy","colab_type":"code","colab":{}},"source":["M = keras.Model(enc.input, dis(enc.output))\n","M.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6DxmnQo5wjhq","colab_type":"code","colab":{}},"source":["optimizer = keras.optimizers.Adam(learning_rate = 0.001)\n","M.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P25v6VxR5PJz","colab_type":"code","colab":{}},"source":["for i in range(20000):\n","  print(i)\n","  M.fit([set1, set2], Y, batch_size = set1.shape[0])\n","  print(M.predict([set1[0:2], set2[0:2]]))\n","  print(Y[0:2])\n","  M.save('/content/drive/My Drive/SOAI/Ass 2 /M.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ixrmbEGq5jx","colab_type":"text"},"source":["#BUILDING THROUGH CORE TENSORFLOW\n","Did not work out as the calculation of derivative with respect to loss came out to be nan. might be due to huge loss metric which is mean squared error of 500 dimensional vector."]},{"cell_type":"code","metadata":{"id":"IAWRSK_ezZwv","colab_type":"code","colab":{}},"source":["resnet = keras.applications.VGG16(include_top=False,weights=\"imagenet\", input_shape=(50,125,3))\n","D1 = keras.layers.Dense(500, activation = 'sigmoid')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lX4lKF3l3RE8","colab_type":"code","colab":{}},"source":["def model():\n","  inp1 = keras.layers.Input(shape=(50,125,3))\n","  inp2 = keras.layers.Input(shape=(50,125,3))\n","\n","  out1 = resnet(inp1)\n","  out1 = keras.layers.Flatten()(out1)\n","  out1 = D1(out1)\n","\n","  out2 = resnet(inp2)\n","  out2 = keras.layers.Flatten()(out2)\n","  out2 = D1(out2)\n","  \n","  model = keras.Model([inp1, inp2], [out1, out2])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLqWFjlBhLu3","colab_type":"code","colab":{}},"source":["def loss_fn(out_same, out_diff):\n","  loss_same = tf.reduce_mean(tf.math.square(tf.math.subtract(out_same[0] , out_same[1])))\n","  loss_diff = -tf.reduce_mean(tf.math.square(tf.math.subtract(out_diff[0] , out_diff[1])))\n","  loss = loss_diff + loss_same\n","  loss = 1/(1+np.exp(loss))\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"btaghwii4XH3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1592660313357,"user_tz":-330,"elapsed":74594,"user":{"displayName":"Himanshu verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhV_rdI62utV8Z0gDZ1mAaRpbbIzTRe8seaH2V0NQ=s64","userId":"11350371483397345534"}},"outputId":"9dc05c93-4dc2-4931-ba8d-ef35dd78ba0d"},"source":["optimizer = keras.optimizers.Adam(learning_rate = 0.001)\n","set1 = tf.convert_to_tensor(set1, dtype=tf.float32)\n","set2 = tf.convert_to_tensor(set2, dtype=tf.float32)\n","set3 = tf.convert_to_tensor(set3, dtype=tf.float32)\n","for i in range(100):\n","  with tf.GradientTape() as Tape:\n","    out_same = m([set1[0:1], set2[0:1]])\n","    out_diff = m([set1, set3])\n","    loss = loss_fn(out_same,  out_diff)\n","  grad = Tape.gradient(loss, m.trainable_variables)\n","  #grad=tf.clip_by_value(grad, -20, 20)\n","  print(grad)\n","  optimizer.apply_gradients(zip(grad, m.trainable_variables))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[<tf.Tensor: shape=(3, 3, 3, 64), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(64,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n","      dtype=float32)>, <tf.Tensor: shape=(3, 3, 64, 64), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(64,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n","      dtype=float32)>, <tf.Tensor: shape=(3, 3, 64, 128), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n","      dtype=float32)>, <tf.Tensor: shape=(3, 3, 128, 128), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n","      dtype=float32)>, <tf.Tensor: shape=(3, 3, 128, 256), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(256,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 256, 256), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(256,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 256, 256), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(256,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 256, 512), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 512, 512), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 512, 512), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 512, 512), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 512, 512), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(3, 3, 512, 512), dtype=float32, numpy=\n","array([[[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]],\n","\n","\n","       [[[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]],\n","\n","        [[nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         ...,\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan],\n","         [nan, nan, nan, ..., nan, nan, nan]]]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n","array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n","       nan, nan, nan, nan, nan], dtype=float32)>, <tf.Tensor: shape=(1536, 500), dtype=float32, numpy=\n","array([[ 0., nan,  0., ...,  0.,  0.,  0.],\n","       [ 0., nan,  0., ...,  0.,  0.,  0.],\n","       [ 0., nan,  0., ...,  0.,  0.,  0.],\n","       ...,\n","       [ 0., nan,  0., ...,  0.,  0.,  0.],\n","       [ 0., nan,  0., ...,  0.,  0.,  0.],\n","       [ 0., nan,  0., ...,  0.,  0.,  0.]], dtype=float32)>, <tf.Tensor: shape=(500,), dtype=float32, numpy=\n","array([ 0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0., nan, nan,  0.,  0., nan,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0., nan,  0.,  0., nan,  0.,  0.,  0., nan,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0., nan,  0.,  0.,  0.,  0., nan,  0.,  0., nan,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan, nan,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","       nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,\n","        0.,  0., nan, nan,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan, nan,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,\n","        0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0., nan,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0., nan, nan,  0.,  0.,  0.,  0.,  0.,  0., nan,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,  0.,\n","        0.,  0.,  0.,  0.,  0., nan,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","        0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)>]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-3f01cdd18bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_same\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mout_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;31m#grad=tf.clip_by_value(grad, -20, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m           data_format=data_format),\n\u001b[0m\u001b[1;32m    593\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[1;32m    594\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1242\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}