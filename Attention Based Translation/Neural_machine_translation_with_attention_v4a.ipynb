{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "nlp-sequence-models",
      "graded_item_id": "n16CQ",
      "launcher_item_id": "npjGi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Neural_machine_translation_with_attention_v4a.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs5vfB__pX9h",
        "outputId": "46b29a21-b9c6-4775-f57f-7bbbcbdc2181"
      },
      "source": [
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "from nmt_utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WouioYT3pX9p",
        "outputId": "ebe3d139-24f8-4a12-9509-0ba625a7185f"
      },
      "source": [
        "m = 10000\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 18811.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9gQIp65pX9s",
        "outputId": "6c5b9bae-fca5-42af-a04f-6ed1c51e92fd"
      },
      "source": [
        "dataset[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('9 may 1998', '1998-05-09'),\n",
              " ('10.11.19', '2019-11-10'),\n",
              " ('9/10/70', '1970-09-10'),\n",
              " ('saturday april 28 1990', '1990-04-28'),\n",
              " ('thursday january 26 1995', '1995-01-26'),\n",
              " ('monday march 7 1983', '1983-03-07'),\n",
              " ('sunday may 22 1988', '1988-05-22'),\n",
              " ('08 jul 2008', '2008-07-08'),\n",
              " ('8 sep 1999', '1999-09-08'),\n",
              " ('thursday january 1 1981', '1981-01-01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dot2E70mpX9v",
        "outputId": "d9872dae-19e8-4cf0-c1ef-14730f264934"
      },
      "source": [
        "Tx = 30\n",
        "Ty = 10\n",
        "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape: (10000, 30)\n",
            "Y.shape: (10000, 10)\n",
            "Xoh.shape: (10000, 30, 37)\n",
            "Yoh.shape: (10000, 10, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBaw2wh1pX92",
        "outputId": "3bd95176-1d64-402c-8071-9dacbf36d130"
      },
      "source": [
        "index = 0\n",
        "print(\"Source date:\", dataset[index][0])\n",
        "print(\"Target date:\", dataset[index][1])\n",
        "print()\n",
        "print(\"Source after preprocessing (indices):\", X[index])\n",
        "print(\"Target after preprocessing (indices):\", Y[index])\n",
        "print()\n",
        "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
        "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source date: 9 may 1998\n",
            "Target date: 1998-05-09\n",
            "\n",
            "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            " 36 36 36 36 36]\n",
            "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
            "\n",
            "Source after preprocessing (one-hot): [[ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 1.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " ..., \n",
            " [ 0.  0.  0. ...,  0.  0.  1.]\n",
            " [ 0.  0.  0. ...,  0.  0.  1.]\n",
            " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
            "Target after preprocessing (one-hot): [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZylON90pX-H"
      },
      "source": [
        "# Defined shared layers as global variables\n",
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De3pSxICpX-K"
      },
      "source": [
        "# GRADED FUNCTION: one_step_attention\n",
        "\n",
        "def one_step_attention(a, s_prev):\n",
        "    \"\"\"\n",
        "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
        "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
        "    \n",
        "    Arguments:\n",
        "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
        "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
        "    \n",
        "    Returns:\n",
        "    context -- context vector, input of the next (post-attention) LSTM cell\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
        "    s_prev = repeator(s_prev)\n",
        "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
        "    # For grading purposes, please list 'a' first and 's_prev' second, in this order.\n",
        "    concat = concatenator([a,s_prev])\n",
        "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
        "    e = densor1(concat)\n",
        "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
        "    energies = densor2(e)\n",
        "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
        "    alphas = activator(energies)\n",
        "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
        "    context = dotor([alphas, a])\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEwm6fSrpX-P"
      },
      "source": [
        "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
        "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
        "\n",
        "# Please note, this is the post attention LSTM cell.  \n",
        "# For the purposes of passing the automatic grader\n",
        "# please do not modify this global variable.  This will be corrected once the automatic grader is also updated.\n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state = True) # post-attention LSTM \n",
        "output_layer = Dense(len(machine_vocab), activation=softmax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZrUe_KMpX-S"
      },
      "source": [
        "# GRADED FUNCTION: model\n",
        "\n",
        "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_a -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
        "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the inputs of your model with a shape (Tx,)\n",
        "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
        "    # for the decoder LSTM with shape (n_s,)\n",
        "    X = Input(shape=(Tx, human_vocab_size))\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Step 1: Define your pre-attention Bi-LSTM. (≈ 1 line)\n",
        "    a = Bidirectional(LSTM(n_a, return_sequences = True) , merge_mode='concat')(X)\n",
        "    \n",
        "    # Step 2: Iterate for Ty steps\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
        "        context = one_step_attention(a, s)\n",
        "        \n",
        "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
        "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
        "        s, _, c = post_activation_LSTM_cell(inputs=context, initial_state =[s,c])\n",
        "        \n",
        "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
        "        outputs.append(out)\n",
        "    \n",
        "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
        "    model = Model(inputs=[X, s0, c0], outputs=outputs)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UknPeTrepX-W"
      },
      "source": [
        "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoMiMvRipX-Y",
        "outputId": "a6b18b7c-aecc-47c1-ebed-c2c5e50a7e4c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "input_4 (InputLayer)             (None, 30, 37)        0                                            \n",
            "____________________________________________________________________________________________________\n",
            "s0 (InputLayer)                  (None, 64)            0                                            \n",
            "____________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional)  (None, 30, 64)        17920       input_4[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)   (None, 30, 64)        0           s0[0][0]                         \n",
            "                                                                   lstm_5[0][0]                     \n",
            "                                                                   lstm_5[1][0]                     \n",
            "                                                                   lstm_5[2][0]                     \n",
            "                                                                   lstm_5[3][0]                     \n",
            "                                                                   lstm_5[4][0]                     \n",
            "                                                                   lstm_5[5][0]                     \n",
            "                                                                   lstm_5[6][0]                     \n",
            "                                                                   lstm_5[7][0]                     \n",
            "                                                                   lstm_5[8][0]                     \n",
            "____________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)      (None, 30, 128)       0           bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[21][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[22][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[23][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[24][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[25][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[26][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[27][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[28][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[29][0]           \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   repeat_vector_1[30][0]           \n",
            "____________________________________________________________________________________________________\n",
            "dense_1 (Dense)                  (None, 30, 10)        1290        concatenate_1[21][0]             \n",
            "                                                                   concatenate_1[22][0]             \n",
            "                                                                   concatenate_1[23][0]             \n",
            "                                                                   concatenate_1[24][0]             \n",
            "                                                                   concatenate_1[25][0]             \n",
            "                                                                   concatenate_1[26][0]             \n",
            "                                                                   concatenate_1[27][0]             \n",
            "                                                                   concatenate_1[28][0]             \n",
            "                                                                   concatenate_1[29][0]             \n",
            "                                                                   concatenate_1[30][0]             \n",
            "____________________________________________________________________________________________________\n",
            "dense_2 (Dense)                  (None, 30, 1)         11          dense_1[21][0]                   \n",
            "                                                                   dense_1[22][0]                   \n",
            "                                                                   dense_1[23][0]                   \n",
            "                                                                   dense_1[24][0]                   \n",
            "                                                                   dense_1[25][0]                   \n",
            "                                                                   dense_1[26][0]                   \n",
            "                                                                   dense_1[27][0]                   \n",
            "                                                                   dense_1[28][0]                   \n",
            "                                                                   dense_1[29][0]                   \n",
            "                                                                   dense_1[30][0]                   \n",
            "____________________________________________________________________________________________________\n",
            "attention_weights (Activation)   (None, 30, 1)         0           dense_2[21][0]                   \n",
            "                                                                   dense_2[22][0]                   \n",
            "                                                                   dense_2[23][0]                   \n",
            "                                                                   dense_2[24][0]                   \n",
            "                                                                   dense_2[25][0]                   \n",
            "                                                                   dense_2[26][0]                   \n",
            "                                                                   dense_2[27][0]                   \n",
            "                                                                   dense_2[28][0]                   \n",
            "                                                                   dense_2[29][0]                   \n",
            "                                                                   dense_2[30][0]                   \n",
            "____________________________________________________________________________________________________\n",
            "dot_1 (Dot)                      multiple              0           attention_weights[21][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[22][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[23][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[24][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[25][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[26][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[27][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[28][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[29][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "                                                                   attention_weights[30][0]         \n",
            "                                                                   bidirectional_4[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "c0 (InputLayer)                  (None, 64)            0                                            \n",
            "____________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                    [(None, 64), (None, 6 33024       dot_1[21][0]                     \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   c0[0][0]                         \n",
            "                                                                   dot_1[22][0]                     \n",
            "                                                                   lstm_5[0][0]                     \n",
            "                                                                   lstm_5[0][2]                     \n",
            "                                                                   dot_1[23][0]                     \n",
            "                                                                   lstm_5[1][0]                     \n",
            "                                                                   lstm_5[1][2]                     \n",
            "                                                                   dot_1[24][0]                     \n",
            "                                                                   lstm_5[2][0]                     \n",
            "                                                                   lstm_5[2][2]                     \n",
            "                                                                   dot_1[25][0]                     \n",
            "                                                                   lstm_5[3][0]                     \n",
            "                                                                   lstm_5[3][2]                     \n",
            "                                                                   dot_1[26][0]                     \n",
            "                                                                   lstm_5[4][0]                     \n",
            "                                                                   lstm_5[4][2]                     \n",
            "                                                                   dot_1[27][0]                     \n",
            "                                                                   lstm_5[5][0]                     \n",
            "                                                                   lstm_5[5][2]                     \n",
            "                                                                   dot_1[28][0]                     \n",
            "                                                                   lstm_5[6][0]                     \n",
            "                                                                   lstm_5[6][2]                     \n",
            "                                                                   dot_1[29][0]                     \n",
            "                                                                   lstm_5[7][0]                     \n",
            "                                                                   lstm_5[7][2]                     \n",
            "                                                                   dot_1[30][0]                     \n",
            "                                                                   lstm_5[8][0]                     \n",
            "                                                                   lstm_5[8][2]                     \n",
            "____________________________________________________________________________________________________\n",
            "dense_4 (Dense)                  (None, 11)            715         lstm_5[0][0]                     \n",
            "                                                                   lstm_5[1][0]                     \n",
            "                                                                   lstm_5[2][0]                     \n",
            "                                                                   lstm_5[3][0]                     \n",
            "                                                                   lstm_5[4][0]                     \n",
            "                                                                   lstm_5[5][0]                     \n",
            "                                                                   lstm_5[6][0]                     \n",
            "                                                                   lstm_5[7][0]                     \n",
            "                                                                   lstm_5[8][0]                     \n",
            "                                                                   lstm_5[9][0]                     \n",
            "====================================================================================================\n",
            "Total params: 52,960\n",
            "Trainable params: 52,960\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ433_47pX-b"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "Here is the summary you should see\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **Total params:**\n",
        "        </td>\n",
        "        <td>\n",
        "         52,960\n",
        "        </td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "        <td>\n",
        "            **Trainable params:**\n",
        "        </td>\n",
        "        <td>\n",
        "         52,960\n",
        "        </td>\n",
        "    </tr>\n",
        "            <tr>\n",
        "        <td>\n",
        "            **Non-trainable params:**\n",
        "        </td>\n",
        "        <td>\n",
        "         0\n",
        "        </td>\n",
        "    </tr>\n",
        "                    <tr>\n",
        "        <td>\n",
        "            **bidirectional_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 64)  \n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "            **repeat_vector_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 64) \n",
        "        </td>\n",
        "    </tr>\n",
        "                <tr>\n",
        "        <td>\n",
        "            **concatenate_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 128) \n",
        "        </td>\n",
        "    </tr>\n",
        "            <tr>\n",
        "        <td>\n",
        "            **attention_weights's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 30, 1)  \n",
        "        </td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "        <td>\n",
        "            **dot_1's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 1, 64)\n",
        "        </td>\n",
        "    </tr>\n",
        "           <tr>\n",
        "        <td>\n",
        "            **dense_3's output shape **\n",
        "        </td>\n",
        "        <td>\n",
        "         (None, 11) \n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCHgzISKpX-b"
      },
      "source": [
        "### START CODE HERE ### (≈2 lines)\n",
        "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay = 0.01) \n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP4fzWHcpX-e"
      },
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JraHetqVpX-i",
        "outputId": "66864302-684e-4b5b-e70a-092474344e37"
      },
      "source": [
        "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 39s - loss: 16.7133 - dense_4_loss_1: 1.2443 - dense_4_loss_2: 1.0145 - dense_4_loss_3: 1.7517 - dense_4_loss_4: 2.6788 - dense_4_loss_5: 0.7891 - dense_4_loss_6: 1.3279 - dense_4_loss_7: 2.6418 - dense_4_loss_8: 0.9764 - dense_4_loss_9: 1.7002 - dense_4_loss_10: 2.5884 - dense_4_acc_1: 0.4944 - dense_4_acc_2: 0.6788 - dense_4_acc_3: 0.3069 - dense_4_acc_4: 0.0802 - dense_4_acc_5: 0.9716 - dense_4_acc_6: 0.2921 - dense_4_acc_7: 0.0551 - dense_4_acc_8: 0.9214 - dense_4_acc_9: 0.2401 - dense_4_acc_10: 0.0988    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe1348e5b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MdKHDkypX-o",
        "outputId": "c20e7eba-eae8-437e-93ea-eee25d302d79"
      },
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "for example in EXAMPLES:\n",
        "    \n",
        "    source = string_to_int(example, Tx, human_vocab)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "    prediction = model.predict([source, s0, c0])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    \n",
        "    print(\"source:\", example)\n",
        "    print(\"output:\", ''.join(output),\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source: 3 May 1979\n",
            "output: 1979-05-03 \n",
            "\n",
            "source: 5 April 09\n",
            "output: 2009-05-05 \n",
            "\n",
            "source: 21th of August 2016\n",
            "output: 2016-08-21 \n",
            "\n",
            "source: Tue 10 Jul 2007\n",
            "output: 2007-07-10 \n",
            "\n",
            "source: Saturday May 9 2018\n",
            "output: 2018-05-09 \n",
            "\n",
            "source: March 3 2001\n",
            "output: 2001-03-03 \n",
            "\n",
            "source: March 3rd 2001\n",
            "output: 2001-03-03 \n",
            "\n",
            "source: 1 March 2001\n",
            "output: 2001-03-01 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}