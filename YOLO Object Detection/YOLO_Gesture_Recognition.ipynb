{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO Gesture Recognition",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grPk1AYlOUd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0963681-b1ac-40f5-865a-0ff0b22d79c4"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# YOLO v3\n",
        "import os\n",
        "import csv\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import PIL\n",
        "import struct\n",
        "import cv2\n",
        "import math\n",
        " \n",
        "import tensorflow as tf\n",
        "'''from skimage.transform import resize\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.models import load_model, Model\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib.patches import Rectangle'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n",
        " \n",
        "# %matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT57JFHlFt9H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "e5e813d7-baa1-4b63-a330-e02758684650"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAdp-RWgJke8"
      },
      "source": [
        "########data augmentation##################\n",
        "# initializing image and corresponding grid dimentions\n",
        "### \n",
        "grid_height = 15\n",
        "grid_width = 20\n",
        "unit_pixel = 8\n",
        "img_height = 120\n",
        "img_width = 160\n",
        " \n",
        " \n",
        " \n",
        " \n",
        "### 15, 20  ,  30, 40  , 60, 80, -- >>  division\n",
        "### 32, 32,   16, 16  , 8, 8   ->> block size\n",
        " \n",
        " \n",
        "## vol up, vol down, back, forward, pause, play\n",
        " \n",
        "## (prob. of object presence , leftup x, left up y, right down x, right down y, pc1, pc2,...)\n",
        "## where object is truly , present ->> train for loss on confidence, and all other things\n",
        "## where no object is present ->>   train only on loss on probability of object present\n",
        " \n",
        "## construction ->> where objcts are present -> (1, ....., 1, ...)\n",
        "##                  where not -> (0, 0,000000)\n",
        " \n",
        "## after training\n",
        "## apply IOU and for probibility of objects greater than 0.5 .\n",
        "## of all the objects remaining, draw them."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SANEJ4J15KY"
      },
      "source": [
        "dct = {'play' : 0, 'stop':1, 'right': 2, 'left': 3, 'volup': 4, 'voldown': 5}\n",
        "dct_rev = {0: 'play', 1:'stop', 2:'right', 3:'left', 4:'volup', 5:'voldown'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HPFV0bpFmxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7f576ae-d3b9-41a2-f092-934f7252bde4"
      },
      "source": [
        "path = '/content/drive/My Drive/SOAI/Ass 3/'\n",
        " \n",
        "lst = os.listdir(path+'data')\n",
        "print(lst)\n",
        " \n",
        " \n",
        "imgs = []\n",
        "outs = []\n",
        "'''\n",
        ". . . . .\n",
        ". . . . .\n",
        ". . . . .\n",
        ". . . . .\n",
        " \n",
        "'''\n",
        "for i in range(len(lst)):\n",
        "  print(lst[i])\n",
        "  csv = pd.read_csv(path +'labels/'+ lst[i] + '.csv')\n",
        "  csv = csv.values\n",
        "  image_names = csv[:, 5]\n",
        "  coordinates = csv[:, 1:5]/4\n",
        "  \n",
        "  out_arr = np.zeros((15,20, 11))\n",
        " \n",
        "  for j in range(len(image_names)):\n",
        "    imgs.append(cv2.resize(cv2.imread(path+'data/' + lst[i] + '/' + image_names[j]) , (160, 120)))\n",
        "    start_x = math.floor(coordinates[j,0]/unit_pixel + 0.5)\n",
        "    start_y = math.floor(coordinates[j,1]/unit_pixel + 0.5)\n",
        "    end_x = math.floor((coordinates[j,0]+coordinates[j, 2])/unit_pixel + 0.5)\n",
        "    end_y = math.floor((coordinates[j,1]+coordinates[j, 3])/unit_pixel + 0.5)\n",
        "    if(end_x == 20):\n",
        "      end_x = 19\n",
        "    if(end_y == 15):\n",
        "      end_y = 14\n",
        "    print(start_y, end_y, start_x, end_x, coordinates[j, :])\n",
        "    out_arr[start_y:end_y+1, start_x:end_x+1, 0] = np.ones((end_y + 1 - start_y, end_x + 1 - start_x))\n",
        "    out_arr[start_y:end_y+1, start_x:end_x+1, 1] = np.full((end_y + 1 - start_y, end_x + 1 - start_x), coordinates[j,0])\n",
        "    out_arr[start_y:end_y+1, start_x:end_x+1, 2] = np.full((end_y + 1 - start_y, end_x + 1 - start_x), coordinates[j,1])\n",
        "    out_arr[start_y:end_y+1, start_x:end_x+1, 3] = np.full((end_y + 1 - start_y, end_x + 1 - start_x), coordinates[j,2])\n",
        "    out_arr[start_y:end_y+1, start_x:end_x+1, 4] = np.full((end_y + 1 - start_y, end_x + 1 - start_x), coordinates[j,3])\n",
        "    k = dct[lst[i]]\n",
        "    out_arr[start_y:end_y+1, start_x:end_x+1, k+5] = np.full((end_y + 1 - start_y, end_x + 1 - start_x), 1)\n",
        "    outs.append(out_arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['voldown', 'left', 'stop', 'play', 'right', 'volup']\n",
            "voldown\n",
            "3 9 15 19 [121.75 20.25 27.75 48.75]\n",
            "0 6 3 8 [20.25 2.0 41.75 48.75]\n",
            "5 12 2 6 [14.25 38.0 36.0 54.75]\n",
            "4 10 8 13 [66.0 30.75 35.0 47.75]\n",
            "7 14 8 12 [62.5 52.75 36.0 60.5]\n",
            "4 10 16 19 [124.25 30.25 34.0 49.75]\n",
            "3 9 14 18 [110.5 26.75 35.0 48.5]\n",
            "0 6 4 9 [28.0 1.25 40.5 46.0]\n",
            "1 7 15 19 [123.25 7.5 36.75 50.5]\n",
            "0 6 9 13 [69.0 1.5 36.0 45.0]\n",
            "0 6 5 9 [38.75 2.25 34.75 49.0]\n",
            "4 10 11 15 [86.5 30.5 32.0 50.5]\n",
            "3 7 11 14 [91.5 22.75 19.5 32.25]\n",
            "5 9 13 15 [100.75 39.25 19.0 30.5]\n",
            "8 12 10 13 [81.75 64.5 21.0 34.5]\n",
            "0 6 7 10 [54.75 2.25 25.25 45.0]\n",
            "4 8 15 18 [120.5 30.0 22.75 35.75]\n",
            "4 8 11 15 [91.5 33.75 27.5 33.5]\n",
            "3 8 7 10 [54.75 25.0 27.75 42.0]\n",
            "3 8 10 13 [80.0 23.25 24.0 41.0]\n",
            "0 5 5 8 [39.25 2.25 25.5 37.25]\n",
            "7 12 15 18 [120.0 53.25 27.25 45.0]\n",
            "7 13 11 15 [86.0 58.25 33.25 45.0]\n",
            "2 9 13 18 [105.0 12.75 36.0 57.5]\n",
            "2 8 14 18 [110.25 16.75 30.5 46.75]\n",
            "3 9 13 17 [106.25 26.75 29.25 43.0]\n",
            "2 6 10 12 [76.0 12.75 18.5 38.25]\n",
            "4 8 13 16 [105.75 32.5 24.75 30.75]\n",
            "4 9 14 17 [112.75 32.75 22.25 36.25]\n",
            "3 8 14 17 [108.25 26.25 26.5 37.25]\n",
            "2 8 13 16 [103.75 19.0 26.75 44.25]\n",
            "2 8 13 17 [104.5 19.75 30.25 43.5]\n",
            "3 8 13 16 [101.5 23.25 28.75 42.75]\n",
            "3 8 5 8 [36.25 26.0 30.25 35.75]\n",
            "5 10 4 8 [31.75 42.75 29.5 40.25]\n",
            "6 10 14 16 [108.5 46.25 22.75 36.5]\n",
            "2 6 6 9 [48.25 15.0 25.75 36.25]\n",
            "5 9 15 18 [121.0 38.0 22.25 34.5]\n",
            "3 7 13 16 [107.0 24.0 20.75 32.5]\n",
            "6 10 6 9 [47.25 48.75 22.75 31.75]\n",
            "5 9 4 7 [35.0 40.75 21.5 30.0]\n",
            "7 12 15 17 [116.0 58.25 22.75 35.5]\n",
            "8 12 15 17 [119.5 63.5 14.25 29.75]\n",
            "4 8 14 16 [110.5 32.5 17.75 33.25]\n",
            "2 6 10 12 [76.0 16.25 23.5 29.5]\n",
            "2 6 11 13 [87.0 19.5 20.5 28.75]\n",
            "3 6 6 9 [51.75 24.0 21.75 27.25]\n",
            "7 11 16 19 [131.5 55.25 18.25 31.75]\n",
            "4 7 14 17 [112.75 29.25 19.5 27.25]\n",
            "4 7 15 17 [117.75 28.5 19.0 24.0]\n",
            "2 5 9 11 [71.0 18.25 17.25 24.25]\n",
            "2 7 4 8 [35.5 15.25 32.25 38.25]\n",
            "8 12 8 11 [63.5 62.0 26.0 33.25]\n",
            "5 9 11 14 [85.75 41.0 24.0 30.75]\n",
            "8 12 9 12 [68.0 63.5 27.25 29.5]\n",
            "8 12 9 12 [68.5 60.0 28.25 33.75]\n",
            "6 11 6 10 [47.75 45.25 32.25 44.25]\n",
            "9 13 8 11 [62.75 68.75 28.25 35.0]\n",
            "10 14 12 15 [99.5 76.0 24.25 37.0]\n",
            "7 11 14 17 [111.75 55.0 26.25 33.75]\n",
            "7 11 12 15 [93.75 52.0 28.25 35.25]\n",
            "5 14 6 14 [46.5 39.0 66.75 76.0]\n",
            "5 12 8 14 [65.5 40.0 45.25 56.5]\n",
            "3 9 3 7 [22.75 22.75 33.75 52.75]\n",
            "5 11 15 18 [117.25 37.0 28.75 50.5]\n",
            "6 11 12 15 [96.25 49.25 27.25 38.75]\n",
            "4 10 13 16 [104.0 33.0 27.25 45.25]\n",
            "5 12 6 11 [51.75 41.75 37.0 53.75]\n",
            "4 11 5 10 [39.25 32.75 39.5 54.0]\n",
            "5 12 7 11 [55.75 39.75 31.75 52.75]\n",
            "4 12 5 9 [36.25 29.25 33.75 67.0]\n",
            "7 11 9 12 [71.0 55.25 24.5 32.75]\n",
            "9 14 4 7 [28.75 73.25 26.75 37.5]\n",
            "8 11 9 12 [74.0 61.5 21.0 24.5]\n",
            "1 8 5 9 [36.0 8.5 32.5 53.0]\n",
            "0 7 11 15 [87.75 2.25 35.0 54.5]\n",
            "2 8 1 5 [7.25 17.0 34.5 45.75]\n",
            "4 8 4 6 [31.0 35.75 19.0 25.0]\n",
            "3 9 4 8 [35.75 23.5 30.75 49.0]\n",
            "4 7 10 12 [79.25 35.75 17.5 20.5]\n",
            "4 14 4 13 [29.5 34.0 75.75 84.0]\n",
            "2 11 7 15 [58.75 12.75 59.5 77.25]\n",
            "1 8 6 12 [51.5 7.25 41.75 53.75]\n",
            "left\n",
            "5 9 14 19 [109.5 41.25 44.5 31.25]\n",
            "3 7 15 19 [116.25 24.5 42.25 31.75]\n",
            "5 9 7 12 [52.0 37.75 42.25 32.75]\n",
            "8 11 9 14 [68.25 62.5 43.5 29.25]\n",
            "7 10 13 18 [107.25 52.5 40.25 25.0]\n",
            "5 8 6 11 [49.0 37.5 41.75 25.75]\n",
            "6 9 4 9 [30.0 49.75 40.0 26.0]\n",
            "4 7 1 7 [11.25 28.5 45.75 26.5]\n",
            "1 5 2 8 [15.0 8.0 46.25 29.5]\n",
            "1 5 14 19 [113.5 9.25 37.25 28.25]\n",
            "12 14 14 18 [113.25 94.0 34.0 26.0]\n",
            "8 11 7 12 [59.5 64.5 35.0 25.75]\n",
            "11 14 11 15 [84.25 86.5 39.5 25.75]\n",
            "11 14 10 15 [82.0 88.0 36.25 24.25]\n",
            "10 14 2 7 [13.25 80.5 44.0 29.25]\n",
            "5 10 3 9 [20.25 41.5 51.5 36.75]\n",
            "4 8 3 9 [25.25 34.5 45.75 30.5]\n",
            "2 6 3 9 [23.0 16.0 45.0 32.75]\n",
            "3 8 11 17 [91.0 22.25 48.25 42.25]\n",
            "3 8 12 18 [94.25 23.75 50.5 37.0]\n",
            "8 11 11 16 [88.0 61.5 42.25 29.5]\n",
            "10 14 11 17 [89.5 83.5 48.5 34.75]\n",
            "2 5 4 8 [28.5 19.25 34.25 24.25]\n",
            "1 4 1 5 [6.0 9.75 35.0 21.75]\n",
            "9 13 8 14 [66.75 71.75 43.5 32.0]\n",
            "7 11 7 12 [55.0 54.25 41.0 34.25]\n",
            "8 11 9 15 [68.75 60.75 49.5 30.0]\n",
            "6 9 5 10 [43.5 45.5 39.5 29.5]\n",
            "3 7 6 12 [50.0 26.25 44.25 33.5]\n",
            "8 11 5 10 [39.25 65.5 39.0 23.5]\n",
            "8 12 6 10 [44.75 67.0 34.0 25.75]\n",
            "5 8 13 19 [104.5 39.75 45.75 23.25]\n",
            "8 11 11 17 [91.25 60.75 42.5 28.5]\n",
            "2 7 1 8 [8.25 19.75 54.5 36.5]\n",
            "1 6 3 10 [21.25 8.5 61.5 40.5]\n",
            "3 7 3 10 [27.25 23.75 54.5 34.25]\n",
            "3 7 11 17 [90.5 20.25 46.5 32.25]\n",
            "5 8 8 13 [63.5 39.75 39.25 25.0]\n",
            "6 10 13 18 [102.75 50.75 42.5 30.5]\n",
            "7 12 11 17 [88.0 58.5 49.75 33.5]\n",
            "9 13 7 13 [53.5 70.0 47.5 30.5]\n",
            "4 8 8 13 [61.5 29.25 45.0 30.75]\n",
            "2 7 12 19 [95.75 17.0 57.25 40.0]\n",
            "5 13 9 19 [73.25 36.75 86.75 68.25]\n",
            "6 12 9 17 [71.0 45.75 62.0 46.25]\n",
            "2 8 5 13 [37.75 14.75 69.75 51.25]\n",
            "3 8 8 16 [67.5 20.0 63.5 43.5]\n",
            "3 9 7 16 [54.0 24.5 72.5 47.5]\n",
            "1 9 2 13 [18.75 9.0 83.75 60.5]\n",
            "2 8 11 19 [84.0 17.0 75.75 50.5]\n",
            "3 8 7 15 [52.5 20.25 65.0 43.75]\n",
            "3 7 1 7 [8.75 25.5 48.0 32.0]\n",
            "8 14 2 9 [18.5 67.25 50.25 41.0]\n",
            "2 7 11 17 [86.25 14.5 53.25 38.5]\n",
            "7 12 9 17 [75.5 52.75 57.25 44.25]\n",
            "0 6 3 14 [24.75 0.5 85.0 50.75]\n",
            "2 5 12 16 [96.0 17.25 28.75 21.0]\n",
            "2 4 14 17 [112.25 14.0 27.25 16.5]\n",
            "7 10 15 19 [119.5 56.25 36.0 27.25]\n",
            "4 9 7 12 [54.25 35.5 41.5 35.0]\n",
            "6 11 2 10 [19.5 46.5 57.0 38.5]\n",
            "7 11 6 13 [45.0 52.5 59.0 39.0]\n",
            "2 8 12 19 [92.75 19.5 61.25 42.25]\n",
            "3 7 5 11 [38.0 25.5 47.0 30.25]\n",
            "1 6 2 9 [14.75 10.75 57.25 38.5]\n",
            "2 6 4 10 [35.5 17.0 48.0 30.5]\n",
            "1 7 3 11 [26.0 9.0 64.0 44.25]\n",
            "3 7 5 12 [40.5 20.25 52.75 39.5]\n",
            "3 8 6 13 [46.0 23.75 54.25 37.5]\n",
            "3 8 6 13 [48.25 21.5 53.0 41.0]\n",
            "3 8 6 13 [47.0 21.5 57.25 39.5]\n",
            "3 9 0 9 [1.5 20.75 72.75 49.0]\n",
            "3 9 0 9 [0.75 20.75 69.5 53.25]\n",
            "5 10 12 18 [99.5 38.25 44.75 39.75]\n",
            "5 10 12 18 [98.75 39.75 48.75 38.25]\n",
            "4 7 11 16 [85.5 33.25 39.75 22.75]\n",
            "4 7 10 14 [80.0 34.5 33.75 19.75]\n",
            "1 4 14 19 [114.75 4.75 36.25 24.0]\n",
            "5 10 5 12 [43.5 42.25 54.0 34.0]\n",
            "7 10 12 17 [94.25 56.0 42.25 27.5]\n",
            "6 10 9 14 [69.0 50.0 46.5 30.0]\n",
            "9 13 8 13 [62.0 75.25 40.5 28.0]\n",
            "5 9 16 19 [126.5 39.75 33.5 30.0]\n",
            "5 8 14 18 [114.25 40.75 33.5 24.5]\n",
            "5 8 6 11 [45.0 38.25 40.25 28.5]\n",
            "6 8 6 11 [51.25 45.75 35.75 21.25]\n",
            "6 8 8 12 [60.75 47.75 31.25 20.0]\n",
            "6 8 9 13 [70.25 45.0 30.5 22.0]\n",
            "11 14 14 18 [113.25 87.75 30.25 22.5]\n",
            "10 12 9 14 [75.0 76.75 34.75 22.0]\n",
            "7 10 6 10 [45.75 57.75 36.75 24.25]\n",
            "11 14 3 7 [20.25 86.5 39.5 30.5]\n",
            "6 9 13 17 [105.0 45.25 34.0 23.75]\n",
            "6 9 5 10 [39.25 44.25 39.0 28.25]\n",
            "7 9 5 9 [43.75 56.75 25.5 14.5]\n",
            "7 10 11 15 [88.0 57.0 28.0 22.0]\n",
            "7 9 8 11 [62.25 57.0 27.75 18.0]\n",
            "5 10 4 11 [29.75 40.75 61.25 40.0]\n",
            "6 11 2 10 [12.0 45.5 65.0 38.75]\n",
            "6 12 5 13 [37.0 49.5 67.5 47.25]\n",
            "4 9 8 16 [67.75 32.75 56.5 37.0]\n",
            "3 8 9 16 [71.75 24.5 59.5 41.0]\n",
            "3 9 9 17 [74.5 27.0 59.5 48.0]\n",
            "11 13 11 13 [86.0 89.25 19.5 13.0]\n",
            "11 13 6 9 [50.0 89.75 19.5 12.0]\n",
            "5 10 10 17 [80.25 37.5 58.75 43.25]\n",
            "1 6 10 16 [79.25 8.5 48.75 37.25]\n",
            "4 7 10 15 [83.0 29.25 36.5 23.5]\n",
            "1 6 5 12 [42.5 11.75 50.0 36.75]\n",
            "6 11 5 14 [41.25 46.0 70.75 43.0]\n",
            "3 7 11 17 [85.0 26.25 49.25 33.25]\n",
            "5 8 5 10 [40.5 36.75 42.25 28.75]\n",
            "3 7 5 10 [37.75 23.0 42.75 32.75]\n",
            "0 5 2 8 [13.5 3.0 49.5 34.0]\n",
            "3 10 0 11 [2.0 24.5 86.0 58.75]\n",
            "3 8 4 12 [30.5 20.75 67.25 43.5]\n",
            "3 8 12 18 [96.5 20.0 51.0 43.5]\n",
            "4 8 6 12 [50.0 28.75 47.75 32.75]\n",
            "4 8 7 13 [53.75 29.0 48.0 34.0]\n",
            "3 7 10 15 [81.0 22.5 41.75 30.75]\n",
            "5 10 2 10 [19.0 42.5 61.0 35.5]\n",
            "3 8 5 11 [41.25 27.75 45.0 33.5]\n",
            "stop\n",
            "3 8 10 15 [79.75 20.25 38.25 45.75]\n",
            "3 7 12 15 [94.75 21.0 27.5 35.5]\n",
            "0 6 9 15 [71.5 0.5 45.25 44.0]\n",
            "6 13 13 18 [100.75 48.75 40.5 56.75]\n",
            "5 12 3 9 [25.75 43.25 46.25 54.5]\n",
            "0 6 1 6 [4.25 0.5 45.0 50.5]\n",
            "3 10 8 14 [67.75 20.25 46.0 56.0]\n",
            "5 9 4 8 [30.5 36.75 32.0 38.25]\n",
            "5 9 12 17 [99.5 39.0 35.0 36.25]\n",
            "5 10 11 15 [87.75 39.0 33.25 41.25]\n",
            "4 10 14 18 [109.5 33.0 33.75 43.25]\n",
            "4 9 9 14 [72.5 31.75 38.5 42.5]\n",
            "5 11 11 16 [90.5 38.75 39.5 48.25]\n",
            "2 9 10 15 [78.25 19.75 39.5 50.5]\n",
            "4 6 14 16 [110.5 28.75 21.25 22.25]\n",
            "2 7 4 8 [33.25 19.75 30.5 33.75]\n",
            "5 14 1 9 [7.75 43.5 65.0 76.5]\n",
            "7 11 12 15 [95.5 53.0 24.5 32.25]\n",
            "7 11 12 15 [94.75 54.75 27.0 30.25]\n",
            "2 8 8 12 [64.5 17.5 35.0 47.75]\n",
            "6 10 11 14 [85.0 46.75 24.0 35.25]\n",
            "2 11 1 9 [7.75 15.5 67.0 70.0]\n",
            "7 12 10 14 [82.75 54.75 30.0 42.25]\n",
            "7 13 11 16 [89.0 55.5 38.25 45.0]\n",
            "6 13 8 13 [63.75 47.0 44.0 54.0]\n",
            "3 10 10 16 [79.5 26.0 46.75 57.25]\n",
            "1 8 9 14 [70.25 7.75 44.5 53.25]\n",
            "5 9 0 3 [0.5 38.0 26.75 35.25]\n",
            "3 8 11 15 [84.5 23.5 34.5 41.25]\n",
            "3 8 11 15 [85.0 24.25 35.0 40.5]\n",
            "10 14 17 19 [139.0 76.5 21.0 35.0]\n",
            "3 7 3 6 [20.5 23.75 28.5 31.25]\n",
            "5 10 11 16 [86.75 38.0 38.5 41.5]\n",
            "1 14 0 15 [3.75 8.75 115.5 111.25]\n",
            "3 8 5 9 [41.0 24.25 29.5 36.25]\n",
            "2 8 2 7 [17.25 14.0 39.25 46.5]\n",
            "5 10 11 16 [89.75 38.25 36.75 40.75]\n",
            "5 8 10 13 [78.0 39.75 27.25 27.25]\n",
            "0 6 13 19 [103.5 0.75 50.0 50.75]\n",
            "8 12 10 13 [77.25 61.5 29.5 30.75]\n",
            "3 8 5 9 [39.5 24.75 35.25 42.75]\n",
            "3 8 4 8 [30.25 22.75 35.75 39.25]\n",
            "6 13 6 15 [47.75 49.5 70.75 58.25]\n",
            "6 12 10 15 [77.5 44.25 43.75 51.75]\n",
            "2 12 7 14 [55.0 15.25 58.25 83.75]\n",
            "5 9 10 15 [77.5 37.25 41.75 36.25]\n",
            "5 10 11 16 [90.5 40.5 40.0 42.75]\n",
            "5 9 12 16 [94.75 37.25 33.5 32.0]\n",
            "5 11 6 12 [50.5 43.0 45.0 48.75]\n",
            "2 10 5 11 [38.0 18.5 52.25 60.25]\n",
            "6 13 1 7 [8.25 49.5 45.5 52.75]\n",
            "0 6 13 19 [100.75 0.25 53.75 50.0]\n",
            "7 12 11 16 [88.25 59.0 36.0 40.25]\n",
            "3 11 3 9 [26.0 27.5 44.5 56.75]\n",
            "4 8 14 19 [114.0 29.25 38.75 36.0]\n",
            "4 10 6 10 [45.0 34.75 38.25 42.75]\n",
            "5 11 10 15 [76.0 39.75 41.75 48.5]\n",
            "10 13 12 15 [99.0 80.25 23.5 21.75]\n",
            "6 9 11 14 [84.0 45.0 26.0 24.0]\n",
            "0 5 7 12 [52.0 0.75 47.75 38.25]\n",
            "1 6 6 11 [48.25 6.75 43.5 42.5]\n",
            "6 11 5 11 [43.5 46.0 40.5 43.0]\n",
            "5 11 5 10 [41.75 41.5 37.25 42.75]\n",
            "6 12 5 10 [37.5 46.75 41.75 46.25]\n",
            "7 12 5 10 [40.25 53.75 42.75 43.5]\n",
            "8 14 8 12 [61.75 66.25 37.75 42.0]\n",
            "6 10 2 7 [18.5 50.5 34.25 30.0]\n",
            "6 10 3 7 [21.25 51.0 33.25 29.5]\n",
            "5 9 5 9 [43.0 41.75 32.0 32.75]\n",
            "5 10 6 11 [45.0 41.75 46.5 41.25]\n",
            "8 11 7 10 [58.0 61.25 25.0 26.75]\n",
            "4 9 9 15 [70.5 30.0 46.0 43.25]\n",
            "4 9 9 15 [73.5 31.75 42.75 41.5]\n",
            "2 7 15 19 [116.25 15.25 42.0 37.25]\n",
            "1 7 13 18 [102.0 11.5 42.75 41.75]\n",
            "2 9 4 10 [33.0 19.5 46.0 52.0]\n",
            "0 7 8 14 [60.5 2.25 50.25 54.5]\n",
            "4 10 6 12 [45.0 28.25 48.75 49.25]\n",
            "4 7 8 12 [64.75 31.75 29.5 22.75]\n",
            "3 6 7 10 [56.75 24.75 26.0 26.0]\n",
            "3 7 7 10 [57.25 26.0 24.75 26.0]\n",
            "1 5 11 16 [86.0 6.5 38.5 31.0]\n",
            "3 6 11 15 [85.0 23.5 31.75 26.0]\n",
            "3 9 2 8 [17.0 21.75 48.75 50.0]\n",
            "play\n",
            "4 13 0 7 [2.0 35.25 54.75 69.75]\n",
            "4 11 12 18 [93.0 32.75 47.5 55.25]\n",
            "2 9 6 13 [51.25 14.0 56.0 61.25]\n",
            "4 7 11 15 [86.75 34.0 31.25 24.75]\n",
            "6 14 4 11 [30.5 45.5 58.75 73.75]\n",
            "3 8 14 18 [110.25 20.75 33.5 44.75]\n",
            "3 9 12 15 [92.0 26.0 30.75 44.25]\n",
            "4 10 11 15 [89.75 30.0 32.0 49.75]\n",
            "6 10 10 15 [81.25 46.0 41.75 36.0]\n",
            "3 7 12 14 [92.0 25.25 23.0 30.75]\n",
            "3 7 10 13 [83.0 26.25 24.5 27.25]\n",
            "7 9 14 16 [115.75 53.0 15.0 20.5]\n",
            "6 9 15 17 [118.75 47.75 14.75 22.0]\n",
            "4 10 10 14 [79.75 31.5 33.0 46.75]\n",
            "3 10 4 8 [32.75 25.5 32.75 54.25]\n",
            "4 10 6 11 [51.25 34.25 33.25 48.75]\n",
            "3 11 8 13 [67.0 24.75 37.25 63.5]\n",
            "4 14 6 13 [44.5 32.25 59.25 87.75]\n",
            "2 14 4 11 [31.25 15.25 55.75 103.75]\n",
            "5 14 11 17 [89.0 36.5 45.25 83.25]\n",
            "4 14 11 17 [90.75 33.75 47.25 86.25]\n",
            "5 14 11 19 [88.5 43.0 66.25 77.0]\n",
            "4 11 11 15 [87.25 31.0 33.0 56.5]\n",
            "2 7 6 9 [47.25 17.75 23.0 37.0]\n",
            "3 7 12 15 [94.75 20.0 25.75 39.5]\n",
            "2 8 12 15 [92.25 18.5 27.0 42.75]\n",
            "2 6 8 11 [67.25 13.75 21.0 31.25]\n",
            "5 7 13 15 [103.5 37.75 14.0 21.5]\n",
            "7 10 2 5 [15.5 57.0 28.0 21.5]\n",
            "3 10 6 10 [46.25 21.25 37.0 57.5]\n",
            "3 11 7 12 [56.0 23.0 40.5 61.25]\n",
            "3 13 11 17 [87.25 21.0 49.25 86.5]\n",
            "6 14 6 13 [49.25 45.75 55.25 74.25]\n",
            "1 7 12 15 [94.25 9.5 28.75 47.5]\n",
            "1 7 7 12 [57.25 6.5 38.75 47.25]\n",
            "4 13 4 10 [28.0 29.5 48.5 72.25]\n",
            "4 9 15 18 [116.5 32.5 26.25 41.0]\n",
            "5 10 12 15 [97.25 41.75 22.75 36.5]\n",
            "2 5 11 13 [87.5 16.25 17.0 24.5]\n",
            "6 11 11 15 [90.25 44.25 32.0 43.5]\n",
            "1 12 5 11 [42.25 11.0 43.0 88.75]\n",
            "1 7 10 14 [80.75 11.75 28.0 42.75]\n",
            "1 7 10 14 [79.0 10.75 30.25 45.25]\n",
            "0 6 8 12 [67.5 0.75 31.25 47.25]\n",
            "0 6 11 15 [91.25 0.25 31.75 51.25]\n",
            "2 9 12 17 [94.0 13.25 42.0 59.0]\n",
            "6 12 4 8 [30.5 50.25 29.5 45.75]\n",
            "0 9 3 8 [21.5 0.25 43.75 69.75]\n",
            "0 7 11 15 [88.0 2.75 29.5 55.75]\n",
            "8 14 10 16 [82.75 63.0 42.5 57.0]\n",
            "5 11 12 15 [93.0 42.5 29.25 48.5]\n",
            "1 10 11 16 [91.0 11.5 39.25 68.25]\n",
            "4 12 14 19 [113.25 35.5 35.0 57.25]\n",
            "3 11 2 7 [16.5 22.75 40.25 65.75]\n",
            "7 14 12 17 [99.75 55.5 37.5 63.5]\n",
            "5 12 2 7 [16.25 36.75 36.75 59.5]\n",
            "3 9 5 8 [40.5 24.5 25.0 48.25]\n",
            "9 14 14 18 [109.5 72.5 32.0 46.75]\n",
            "3 9 10 13 [77.25 24.5 26.75 48.0]\n",
            "8 13 18 19 [140.5 61.5 19.5 42.0]\n",
            "7 11 14 16 [113.0 57.5 18.0 28.0]\n",
            "7 11 14 17 [115.0 56.25 17.25 28.5]\n",
            "6 11 10 13 [82.25 48.75 23.25 43.0]\n",
            "7 10 5 8 [37.75 53.75 23.25 28.75]\n",
            "4 9 10 14 [78.75 32.25 30.0 38.0]\n",
            "5 11 2 6 [14.25 42.75 29.75 47.25]\n",
            "3 8 15 18 [120.0 21.5 25.0 39.5]\n",
            "8 13 13 17 [105.0 67.25 30.25 40.25]\n",
            "7 13 9 12 [72.5 52.5 24.25 48.0]\n",
            "8 14 12 17 [96.5 63.0 41.25 57.0]\n",
            "5 10 8 11 [64.25 36.0 25.75 41.25]\n",
            "5 14 8 15 [63.5 36.75 56.75 83.25]\n",
            "5 14 8 14 [62.0 36.75 52.5 83.25]\n",
            "right\n",
            "2 6 5 11 [39.5 15.5 47.25 29.25]\n",
            "0 5 12 17 [97.0 2.25 42.0 34.0]\n",
            "6 10 12 18 [96.25 45.75 44.75 32.0]\n",
            "5 9 3 9 [24.25 43.75 46.75 25.75]\n",
            "3 6 3 9 [26.5 20.5 42.25 28.25]\n",
            "1 5 1 6 [4.25 8.5 44.5 28.0]\n",
            "6 8 12 15 [93.5 44.5 27.75 19.75]\n",
            "6 8 12 15 [92.25 51.25 26.25 16.5]\n",
            "6 8 14 16 [111.25 48.5 20.5 15.5]\n",
            "2 5 12 17 [99.5 17.5 38.0 22.75]\n",
            "6 9 12 16 [94.5 49.0 32.0 20.25]\n",
            "2 4 11 16 [89.5 15.5 36.5 19.0]\n",
            "8 12 9 14 [75.0 67.0 36.5 27.25]\n",
            "8 11 9 14 [71.5 61.75 44.25 30.0]\n",
            "5 9 3 9 [27.75 39.0 46.0 30.25]\n",
            "1 5 2 8 [15.75 7.75 49.0 31.25]\n",
            "6 8 11 14 [84.0 44.25 29.25 23.0]\n",
            "6 10 14 19 [110.5 50.25 39.5 26.0]\n",
            "3 7 12 17 [92.75 21.5 44.75 32.5]\n",
            "4 8 12 18 [97.5 32.25 45.75 32.0]\n",
            "6 10 12 19 [94.75 47.25 59.5 36.5]\n",
            "6 10 12 16 [94.75 50.25 29.5 27.75]\n",
            "7 9 11 15 [91.25 52.5 30.25 20.5]\n",
            "4 7 12 15 [95.0 34.5 27.25 23.25]\n",
            "4 7 12 16 [92.0 32.25 35.75 22.75]\n",
            "2 9 5 14 [36.5 18.5 73.25 51.75]\n",
            "5 9 11 16 [85.5 41.0 39.5 29.5]\n",
            "6 9 11 16 [89.5 47.0 39.0 27.5]\n",
            "5 9 11 17 [86.0 43.75 49.75 28.5]\n",
            "7 10 13 18 [106.25 55.5 41.0 25.75]\n",
            "1 6 4 11 [31.75 8.75 56.25 37.0]\n",
            "1 6 5 11 [38.25 9.25 52.75 35.0]\n",
            "1 6 5 11 [37.0 11.25 52.0 37.5]\n",
            "0 4 10 16 [78.75 0.5 46.0 33.0]\n",
            "0 4 11 17 [85.25 2.25 49.25 33.5]\n",
            "0 5 1 8 [9.5 3.5 51.75 34.0]\n",
            "7 10 0 7 [3.25 55.0 53.5 28.0]\n",
            "11 14 6 12 [47.5 89.25 51.25 30.75]\n",
            "9 13 7 14 [56.75 74.0 52.75 33.0]\n",
            "11 14 9 14 [69.75 87.25 43.75 28.75]\n",
            "1 7 9 16 [74.5 10.75 55.5 43.0]\n",
            "1 8 5 15 [42.75 7.0 77.25 53.75]\n",
            "1 8 4 13 [31.25 4.5 75.5 55.75]\n",
            "2 9 4 13 [30.25 17.0 77.0 54.25]\n",
            "4 11 6 14 [48.25 34.5 67.25 49.5]\n",
            "4 7 1 6 [6.0 28.5 41.5 29.5]\n",
            "0 4 8 14 [62.0 0.75 48.75 34.0]\n",
            "1 6 4 10 [28.75 10.0 51.75 40.25]\n",
            "1 5 4 10 [28.75 5.5 52.0 35.75]\n",
            "2 5 4 10 [30.0 12.0 48.0 30.5]\n",
            "1 5 4 10 [31.75 9.0 49.0 33.75]\n",
            "3 6 2 8 [14.5 22.25 47.75 28.75]\n",
            "0 4 11 15 [85.25 3.75 31.25 28.5]\n",
            "1 8 0 12 [3.25 10.75 91.25 54.25]\n",
            "2 8 0 11 [0.5 13.25 90.75 49.75]\n",
            "4 11 7 18 [57.75 30.0 83.25 54.25]\n",
            "4 13 7 19 [55.0 32.5 98.25 69.75]\n",
            "5 14 7 18 [57.25 39.75 86.0 69.5]\n",
            "5 14 7 18 [53.0 39.0 90.5 71.75]\n",
            "4 11 10 17 [81.25 31.5 57.5 53.5]\n",
            "6 9 11 15 [90.5 44.25 31.0 28.0]\n",
            "5 9 11 15 [91.25 41.5 31.75 28.25]\n",
            "5 9 11 16 [90.5 42.0 38.75 26.5]\n",
            "6 9 11 16 [87.5 44.5 36.5 27.0]\n",
            "6 9 11 16 [90.5 47.25 34.5 24.0]\n",
            "6 9 11 16 [89.75 51.5 36.25 22.75]\n",
            "6 9 12 16 [92.75 49.0 34.75 26.0]\n",
            "6 9 11 16 [90.0 50.0 37.0 24.25]\n",
            "6 9 12 17 [95.0 50.25 39.0 24.25]\n",
            "7 11 5 10 [37.75 59.0 44.5 28.25]\n",
            "8 10 10 14 [81.75 65.25 27.75 16.0]\n",
            "8 10 11 15 [89.5 60.75 28.0 16.75]\n",
            "6 14 0 10 [1.25 48.25 76.25 64.0]\n",
            "7 13 13 19 [103.75 59.25 49.25 42.0]\n",
            "5 9 3 10 [25.75 37.75 52.0 33.5]\n",
            "3 7 3 9 [21.25 20.75 49.5 33.25]\n",
            "3 6 6 11 [46.75 23.0 38.0 24.25]\n",
            "3 6 8 13 [62.0 25.75 38.75 22.0]\n",
            "4 8 12 17 [95.25 35.25 41.25 28.0]\n",
            "4 8 11 16 [90.5 35.5 40.75 25.75]\n",
            "10 14 9 13 [70.0 81.25 35.75 28.0]\n",
            "8 11 8 13 [66.5 61.5 37.75 26.5]\n",
            "4 7 5 9 [38.0 33.75 32.5 19.5]\n",
            "7 9 4 7 [32.75 59.75 24.25 15.0]\n",
            "9 11 7 9 [53.5 70.0 22.25 15.0]\n",
            "9 11 7 10 [54.25 73.0 22.0 15.25]\n",
            "9 10 7 10 [59.5 69.25 20.75 14.0]\n",
            "9 11 8 11 [65.75 74.0 21.25 13.5]\n",
            "10 12 11 14 [85.75 78.25 22.75 14.5]\n",
            "8 9 11 15 [89.5 60.0 27.5 14.25]\n",
            "6 9 11 14 [85.75 49.5 28.0 19.25]\n",
            "5 8 8 11 [65.0 42.25 26.5 20.0]\n",
            "7 9 3 7 [25.75 53.0 27.25 16.5]\n",
            "7 10 0 3 [1.0 53.75 22.75 26.75]\n",
            "7 10 14 19 [114.25 56.0 42.0 24.5]\n",
            "5 7 12 16 [95.5 38.75 35.5 18.75]\n",
            "8 10 9 13 [71.75 60.0 31.5 19.5]\n",
            "11 14 13 17 [102.25 91.75 32.75 22.0]\n",
            "7 11 13 18 [102.75 57.75 44.25 29.5]\n",
            "4 7 12 17 [96.0 30.0 38.75 27.75]\n",
            "8 12 5 11 [41.5 61.5 47.25 33.0]\n",
            "6 9 4 9 [31.75 46.5 36.25 24.5]\n",
            "2 8 4 12 [28.75 13.25 70.0 46.75]\n",
            "7 12 10 18 [81.75 53.5 60.75 45.0]\n",
            "4 9 5 12 [39.25 31.75 58.75 41.0]\n",
            "6 11 9 16 [70.25 51.0 61.25 36.25]\n",
            "4 8 11 17 [87.25 29.25 52.0 36.5]\n",
            "2 8 6 15 [46.75 17.0 74.25 50.25]\n",
            "6 13 2 12 [12.75 50.25 82.5 53.25]\n",
            "6 13 10 19 [76.75 48.75 74.25 52.75]\n",
            "5 9 11 16 [88.25 42.75 38.0 29.75]\n",
            "9 13 13 18 [103.5 75.5 41.5 28.25]\n",
            "3 7 7 14 [58.0 22.75 54.75 32.25]\n",
            "5 9 2 9 [13.5 36.0 60.5 37.5]\n",
            "0 5 4 11 [29.25 3.25 62.25 39.5]\n",
            "1 6 12 19 [93.5 6.25 63.75 43.75]\n",
            "0 5 10 17 [76.0 1.5 58.75 42.0]\n",
            "5 9 7 14 [54.25 36.75 56.0 38.75]\n",
            "6 10 13 19 [101.5 45.5 56.0 37.0]\n",
            "5 9 13 19 [102.0 39.0 52.0 35.75]\n",
            "3 8 12 19 [94.25 20.0 65.75 43.5]\n",
            "8 14 12 19 [92.5 63.75 64.5 54.75]\n",
            "4 8 7 14 [54.25 32.25 61.25 35.0]\n",
            "6 10 11 17 [88.0 48.0 51.25 35.5]\n",
            "10 14 12 19 [98.0 77.75 56.5 42.25]\n",
            "4 9 5 12 [38.5 33.0 55.75 37.5]\n",
            "4 8 11 17 [90.25 34.5 45.5 30.25]\n",
            "3 5 12 15 [92.75 23.5 28.25 19.5]\n",
            "5 7 6 9 [50.0 39.0 25.5 16.0]\n",
            "6 8 9 11 [68.0 49.25 20.75 12.0]\n",
            "6 8 11 14 [88.5 48.75 21.75 12.5]\n",
            "6 7 7 9 [54.5 48.25 19.5 11.25]\n",
            "8 10 1 4 [7.0 62.0 22.75 15.75]\n",
            "7 9 2 5 [18.0 57.0 23.25 15.0]\n",
            "volup\n",
            "2 8 12 17 [99.5 15.5 37.5 49.25]\n",
            "2 11 10 16 [78.25 13.25 50.5 75.0]\n",
            "3 13 6 14 [50.5 26.75 59.5 78.25]\n",
            "7 14 4 11 [34.25 55.5 57.25 64.5]\n",
            "4 9 10 14 [83.5 31.25 30.0 42.25]\n",
            "2 9 2 7 [12.5 16.0 44.75 58.25]\n",
            "4 11 2 6 [16.5 35.5 34.0 52.75]\n",
            "3 9 8 12 [60.75 27.25 38.75 47.25]\n",
            "3 9 8 12 [60.5 22.75 36.0 52.0]\n",
            "4 9 11 15 [89.5 30.75 33.75 39.0]\n",
            "4 10 11 15 [90.5 31.75 32.0 44.75]\n",
            "6 12 5 10 [41.75 46.0 34.5 52.0]\n",
            "5 11 4 9 [33.75 39.5 38.25 52.25]\n",
            "8 14 4 10 [29.5 65.0 51.0 55.0]\n",
            "5 11 12 17 [95.5 37.25 39.0 52.0]\n",
            "3 10 9 13 [70.25 25.0 37.25 54.75]\n",
            "4 10 9 14 [75.5 28.5 35.5 50.5]\n",
            "3 6 5 9 [43.5 22.5 27.75 28.0]\n",
            "2 7 10 14 [78.25 16.25 30.5 38.75]\n",
            "2 7 11 15 [90.5 15.0 32.0 39.5]\n",
            "4 8 8 11 [62.25 30.0 29.25 36.75]\n",
            "2 7 12 15 [93.5 13.5 30.25 45.75]\n",
            "1 7 8 13 [65.0 10.0 35.25 42.75]\n",
            "8 14 1 6 [10.0 60.0 36.75 52.25]\n",
            "7 10 6 8 [45.75 52.75 19.0 23.25]\n",
            "2 9 1 5 [7.25 14.5 32.0 54.0]\n",
            "2 9 2 6 [14.5 15.5 36.0 55.75]\n",
            "1 8 11 17 [89.0 6.5 45.0 57.0]\n",
            "2 8 10 16 [82.25 13.25 45.0 53.0]\n",
            "2 13 7 16 [58.0 17.25 67.75 89.5]\n",
            "9 14 2 8 [12.0 75.5 49.0 44.5]\n",
            "9 14 2 8 [17.25 73.0 45.75 47.0]\n",
            "3 10 3 8 [26.0 23.0 37.5 53.0]\n",
            "4 11 4 8 [31.25 33.75 33.5 50.25]\n",
            "0 7 2 8 [18.0 0.5 45.75 57.25]\n",
            "5 10 3 6 [24.25 42.0 25.75 35.75]\n",
            "2 5 8 11 [62.75 13.25 23.5 28.25]\n",
            "2 6 3 6 [22.5 17.0 23.25 31.5]\n",
            "2 6 3 5 [20.5 15.5 22.75 33.75]\n",
            "9 13 4 7 [32.5 68.5 25.25 35.25]\n",
            "8 13 4 8 [34.75 63.0 29.75 38.5]\n",
            "6 11 9 12 [68.0 51.5 25.0 40.25]\n",
            "2 7 9 13 [71.0 18.75 29.5 35.25]\n",
            "3 9 1 6 [10.75 20.0 33.75 52.25]\n",
            "7 13 5 8 [36.5 57.25 28.5 45.5]\n",
            "7 13 14 17 [113.0 58.5 25.0 44.0]\n",
            "3 8 13 16 [102.75 21.5 24.75 41.5]\n",
            "2 7 12 15 [95.75 13.5 27.25 40.5]\n",
            "2 7 12 15 [93.25 16.75 26.5 37.75]\n",
            "4 8 9 12 [75.0 29.0 22.0 35.0]\n",
            "5 9 6 9 [46.0 43.0 22.0 32.75]\n",
            "8 13 6 9 [48.25 65.0 24.25 40.5]\n",
            "4 9 2 5 [14.0 34.5 29.75 39.75]\n",
            "8 14 10 16 [80.5 63.5 47.0 56.5]\n",
            "6 12 3 9 [25.0 48.0 46.75 48.5]\n",
            "6 12 8 13 [67.25 44.75 38.75 51.0]\n",
            "4 10 16 19 [125.75 32.25 34.25 51.25]\n",
            "4 10 8 14 [62.0 29.0 46.5 50.25]\n",
            "5 9 4 7 [31.75 38.75 26.75 33.25]\n",
            "7 14 10 15 [76.25 58.5 41.5 61.5]\n",
            "11 14 12 15 [99.5 87.75 22.0 30.75]\n",
            "11 14 12 15 [99.0 84.75 22.25 29.5]\n",
            "6 13 4 10 [31.5 51.5 44.75 51.5]\n",
            "5 10 6 10 [51.75 43.0 29.75 34.5]\n",
            "5 12 2 7 [16.75 41.0 35.75 51.25]\n",
            "5 11 10 13 [76.5 42.25 27.25 44.0]\n",
            "7 12 13 17 [107.0 53.0 32.0 43.5]\n",
            "12 14 17 19 [136.75 93.75 17.5 21.25]\n",
            "11 14 15 18 [123.75 88.75 19.25 21.25]\n",
            "7 14 8 13 [65.75 55.5 38.25 64.5]\n",
            "5 10 8 12 [63.5 38.25 29.5 44.0]\n",
            "6 14 9 15 [75.75 45.25 45.0 74.75]\n",
            "2 12 6 12 [50.25 16.0 46.25 77.75]\n",
            "6 14 13 19 [100.5 50.25 56.25 69.75]\n",
            "8 14 16 19 [126.0 61.25 34.0 56.0]\n",
            "0 8 12 18 [96.5 1.25 46.75 59.5]\n",
            "1 9 12 18 [98.25 4.5 43.5 66.75]\n",
            "3 13 15 19 [116.5 27.75 43.5 75.75]\n",
            "0 10 6 13 [50.75 1.25 50.5 78.75]\n",
            "8 12 14 17 [113.5 62.25 22.0 31.0]\n",
            "7 11 15 18 [121.5 54.5 23.25 29.75]\n",
            "4 9 11 14 [85.75 29.25 28.0 42.5]\n",
            "2 9 6 12 [48.25 13.0 45.25 62.75]\n",
            "9 13 12 15 [95.0 69.25 23.0 31.75]\n",
            "3 9 9 12 [70.25 26.25 22.75 47.25]\n",
            "1 11 7 12 [54.5 8.0 44.25 77.25]\n",
            "0 10 5 11 [39.25 2.75 48.25 80.5]\n",
            "0 9 12 17 [95.5 3.75 39.5 69.0]\n",
            "7 14 12 17 [95.25 59.0 37.5 61.0]\n",
            "4 13 8 13 [62.25 28.5 42.0 74.0]\n",
            "7 14 13 18 [100.5 55.0 44.0 65.0]\n",
            "8 14 12 18 [99.75 60.0 42.5 60.0]\n",
            "6 14 0 7 [1.75 47.0 52.25 65.75]\n",
            "8 14 0 7 [1.25 61.25 51.5 58.75]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WYGuxW5Rg91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c4a646f-a23b-4b39-e698-0a19b57930ed"
      },
      "source": [
        "imgs = np.asarray(imgs)\n",
        "outs = np.asarray(outs)\n",
        "print(imgs.shape, outs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(590, 120, 160, 3) (590, 15, 20, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSuaqNBTTKsQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc3c2007-0a4c-4cfc-9898-a4fa4b3ca472"
      },
      "source": [
        "xTrain, xTest, yTrain, yTest = train_test_split(imgs, outs, test_size = 0.2, random_state = 0)\n",
        "print(xTrain.shape, yTrain.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(472, 120, 160, 3) (472, 15, 20, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vvy59gaBwUX"
      },
      "source": [
        "\n",
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        \n",
        "        if conv['stride'] > 1: x = tf.keras.layers.ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = tf.keras.layers.Conv2D(conv['filter'], \n",
        "                   conv['kernel'], \n",
        "                   strides=conv['stride'], \n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']), \n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = tf.keras.layers.BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = tf.keras.layers.LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return tf.keras.layers.add([skip_connection, x]) if skip else x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwkO2I1FDfLZ"
      },
      "source": [
        "\n",
        "# creating the YOLO model\n",
        "def make_yolov3_model():\n",
        "    input_image = tf.keras.layers.Input(shape=(img_height,img_width, 3))\n",
        "\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "        \n",
        "    skip_36 = x\n",
        "        \n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "        \n",
        "    skip_61 = x\n",
        "        \n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "        \n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 11, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    '''\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 11, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "    \"\"\"\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 4, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "    \"\"\"\n",
        "    '''\n",
        "    prob_of_object = tf.keras.layers.Lambda(lambda x : x[:,:,:,0:1])(x)\n",
        "    prob_of_object = tf.keras.layers.Activation('sigmoid')(prob_of_object)\n",
        "    \n",
        "    coord = tf.keras.layers.Lambda(lambda x : x[:,:,:,1:5])(x)\n",
        "    \n",
        "    classes = tf.keras.layers.Lambda(lambda x : x[:,:,:,5:11])(x)\n",
        "    classes = tf.keras.layers.Activation('softmax')(classes)\n",
        "    concat = tf.keras.layers.Concatenate(axis = -1)([prob_of_object, coord, classes])\n",
        "    model = tf.keras.Model(input_image, outputs = concat)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSLQUS9Mab85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0913ba5b-3266-407b-a135-983f7b818df9"
      },
      "source": [
        "yolov3 = make_yolov3_model()\n",
        "yolov3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           [(None, 120, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_0 (Conv2D)                 (None, 120, 160, 32) 864         input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_0 (BatchNormalization)    (None, 120, 160, 32) 128         conv_0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_0 (LeakyReLU)             (None, 120, 160, 32) 0           bnorm_0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_31 (ZeroPadding2 (None, 121, 161, 32) 0           leaky_0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 60, 80, 64)   18432       zero_padding2d_31[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_1 (BatchNormalization)    (None, 60, 80, 64)   256         conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_1 (LeakyReLU)             (None, 60, 80, 64)   0           bnorm_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 60, 80, 32)   2048        leaky_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_2 (BatchNormalization)    (None, 60, 80, 32)   128         conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_2 (LeakyReLU)             (None, 60, 80, 32)   0           bnorm_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 60, 80, 64)   18432       leaky_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_3 (BatchNormalization)    (None, 60, 80, 64)   256         conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_3 (LeakyReLU)             (None, 60, 80, 64)   0           bnorm_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_232 (Add)                   (None, 60, 80, 64)   0           leaky_1[0][0]                    \n",
            "                                                                 leaky_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_32 (ZeroPadding2 (None, 61, 81, 64)   0           add_232[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_5 (Conv2D)                 (None, 30, 40, 128)  73728       zero_padding2d_32[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_5 (BatchNormalization)    (None, 30, 40, 128)  512         conv_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_5 (LeakyReLU)             (None, 30, 40, 128)  0           bnorm_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_6 (Conv2D)                 (None, 30, 40, 64)   8192        leaky_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_6 (BatchNormalization)    (None, 30, 40, 64)   256         conv_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_6 (LeakyReLU)             (None, 30, 40, 64)   0           bnorm_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7 (Conv2D)                 (None, 30, 40, 128)  73728       leaky_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_7 (BatchNormalization)    (None, 30, 40, 128)  512         conv_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_7 (LeakyReLU)             (None, 30, 40, 128)  0           bnorm_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_233 (Add)                   (None, 30, 40, 128)  0           leaky_5[0][0]                    \n",
            "                                                                 leaky_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_9 (Conv2D)                 (None, 30, 40, 64)   8192        add_233[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_9 (BatchNormalization)    (None, 30, 40, 64)   256         conv_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_9 (LeakyReLU)             (None, 30, 40, 64)   0           bnorm_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_10 (Conv2D)                (None, 30, 40, 128)  73728       leaky_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_10 (BatchNormalization)   (None, 30, 40, 128)  512         conv_10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_10 (LeakyReLU)            (None, 30, 40, 128)  0           bnorm_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_234 (Add)                   (None, 30, 40, 128)  0           add_233[0][0]                    \n",
            "                                                                 leaky_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_33 (ZeroPadding2 (None, 31, 41, 128)  0           add_234[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_12 (Conv2D)                (None, 15, 20, 256)  294912      zero_padding2d_33[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_12 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_12 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_13 (Conv2D)                (None, 15, 20, 128)  32768       leaky_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_13 (BatchNormalization)   (None, 15, 20, 128)  512         conv_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_13 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_14 (Conv2D)                (None, 15, 20, 256)  294912      leaky_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_14 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_14 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_235 (Add)                   (None, 15, 20, 256)  0           leaky_12[0][0]                   \n",
            "                                                                 leaky_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_16 (Conv2D)                (None, 15, 20, 128)  32768       add_235[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_16 (BatchNormalization)   (None, 15, 20, 128)  512         conv_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_16 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_17 (Conv2D)                (None, 15, 20, 256)  294912      leaky_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_17 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_17 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_236 (Add)                   (None, 15, 20, 256)  0           add_235[0][0]                    \n",
            "                                                                 leaky_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_19 (Conv2D)                (None, 15, 20, 128)  32768       add_236[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_19 (BatchNormalization)   (None, 15, 20, 128)  512         conv_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_19 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_20 (Conv2D)                (None, 15, 20, 256)  294912      leaky_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_20 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_20 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_237 (Add)                   (None, 15, 20, 256)  0           add_236[0][0]                    \n",
            "                                                                 leaky_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_22 (Conv2D)                (None, 15, 20, 128)  32768       add_237[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_22 (BatchNormalization)   (None, 15, 20, 128)  512         conv_22[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_22 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_23 (Conv2D)                (None, 15, 20, 256)  294912      leaky_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_23 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_23 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_238 (Add)                   (None, 15, 20, 256)  0           add_237[0][0]                    \n",
            "                                                                 leaky_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_25 (Conv2D)                (None, 15, 20, 128)  32768       add_238[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_25 (BatchNormalization)   (None, 15, 20, 128)  512         conv_25[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_25 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_26 (Conv2D)                (None, 15, 20, 256)  294912      leaky_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_26 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_26[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_26 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_239 (Add)                   (None, 15, 20, 256)  0           add_238[0][0]                    \n",
            "                                                                 leaky_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_28 (Conv2D)                (None, 15, 20, 128)  32768       add_239[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_28 (BatchNormalization)   (None, 15, 20, 128)  512         conv_28[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_28 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_29 (Conv2D)                (None, 15, 20, 256)  294912      leaky_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_29 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_29[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_29 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_240 (Add)                   (None, 15, 20, 256)  0           add_239[0][0]                    \n",
            "                                                                 leaky_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_31 (Conv2D)                (None, 15, 20, 128)  32768       add_240[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_31 (BatchNormalization)   (None, 15, 20, 128)  512         conv_31[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_31 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_32 (Conv2D)                (None, 15, 20, 256)  294912      leaky_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_32 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_32[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_32 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_241 (Add)                   (None, 15, 20, 256)  0           add_240[0][0]                    \n",
            "                                                                 leaky_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_34 (Conv2D)                (None, 15, 20, 128)  32768       add_241[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_34 (BatchNormalization)   (None, 15, 20, 128)  512         conv_34[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_34 (LeakyReLU)            (None, 15, 20, 128)  0           bnorm_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_35 (Conv2D)                (None, 15, 20, 256)  294912      leaky_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_35 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_35[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_35 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_242 (Add)                   (None, 15, 20, 256)  0           add_241[0][0]                    \n",
            "                                                                 leaky_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_37 (Conv2D)                (None, 15, 20, 512)  1179648     add_242[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_37 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_37[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_37 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_38 (Conv2D)                (None, 15, 20, 256)  131072      leaky_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_38 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_38[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_38 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_39 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_39 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_39[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_39 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_243 (Add)                   (None, 15, 20, 512)  0           leaky_37[0][0]                   \n",
            "                                                                 leaky_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_41 (Conv2D)                (None, 15, 20, 256)  131072      add_243[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_41 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_41[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_41 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_42 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_42 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_42[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_42 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_244 (Add)                   (None, 15, 20, 512)  0           add_243[0][0]                    \n",
            "                                                                 leaky_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_44 (Conv2D)                (None, 15, 20, 256)  131072      add_244[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_44 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_44[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_44 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_45 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_45 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_45[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_45 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_245 (Add)                   (None, 15, 20, 512)  0           add_244[0][0]                    \n",
            "                                                                 leaky_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_47 (Conv2D)                (None, 15, 20, 256)  131072      add_245[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_47 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_47[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_47 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_48 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_48 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_48[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_48 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_246 (Add)                   (None, 15, 20, 512)  0           add_245[0][0]                    \n",
            "                                                                 leaky_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_50 (Conv2D)                (None, 15, 20, 256)  131072      add_246[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_50 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_50[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_50 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_51 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_51 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_51[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_51 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_247 (Add)                   (None, 15, 20, 512)  0           add_246[0][0]                    \n",
            "                                                                 leaky_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_53 (Conv2D)                (None, 15, 20, 256)  131072      add_247[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_53 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_53[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_53 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_54 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_54 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_54[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_54 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_248 (Add)                   (None, 15, 20, 512)  0           add_247[0][0]                    \n",
            "                                                                 leaky_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_56 (Conv2D)                (None, 15, 20, 256)  131072      add_248[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_56 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_56[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_56 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_57 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_57 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_57[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_57 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_249 (Add)                   (None, 15, 20, 512)  0           add_248[0][0]                    \n",
            "                                                                 leaky_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_59 (Conv2D)                (None, 15, 20, 256)  131072      add_249[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_59 (BatchNormalization)   (None, 15, 20, 256)  1024        conv_59[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_59 (LeakyReLU)            (None, 15, 20, 256)  0           bnorm_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_60 (Conv2D)                (None, 15, 20, 512)  1179648     leaky_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_60 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_60[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_60 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_250 (Add)                   (None, 15, 20, 512)  0           add_249[0][0]                    \n",
            "                                                                 leaky_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_62 (Conv2D)                (None, 15, 20, 1024) 4718592     add_250[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_62 (BatchNormalization)   (None, 15, 20, 1024) 4096        conv_62[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_62 (LeakyReLU)            (None, 15, 20, 1024) 0           bnorm_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_63 (Conv2D)                (None, 15, 20, 512)  524288      leaky_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_63 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_63[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_63 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_64 (Conv2D)                (None, 15, 20, 1024) 4718592     leaky_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_64 (BatchNormalization)   (None, 15, 20, 1024) 4096        conv_64[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_64 (LeakyReLU)            (None, 15, 20, 1024) 0           bnorm_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_251 (Add)                   (None, 15, 20, 1024) 0           leaky_62[0][0]                   \n",
            "                                                                 leaky_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_66 (Conv2D)                (None, 15, 20, 512)  524288      add_251[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_66 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_66[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_66 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_67 (Conv2D)                (None, 15, 20, 1024) 4718592     leaky_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_67 (BatchNormalization)   (None, 15, 20, 1024) 4096        conv_67[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_67 (LeakyReLU)            (None, 15, 20, 1024) 0           bnorm_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_252 (Add)                   (None, 15, 20, 1024) 0           add_251[0][0]                    \n",
            "                                                                 leaky_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_69 (Conv2D)                (None, 15, 20, 512)  524288      add_252[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_69 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_69[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_69 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_70 (Conv2D)                (None, 15, 20, 1024) 4718592     leaky_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_70 (BatchNormalization)   (None, 15, 20, 1024) 4096        conv_70[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_70 (LeakyReLU)            (None, 15, 20, 1024) 0           bnorm_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_253 (Add)                   (None, 15, 20, 1024) 0           add_252[0][0]                    \n",
            "                                                                 leaky_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_72 (Conv2D)                (None, 15, 20, 512)  524288      add_253[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_72 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_72[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_72 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_73 (Conv2D)                (None, 15, 20, 1024) 4718592     leaky_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_73 (BatchNormalization)   (None, 15, 20, 1024) 4096        conv_73[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_73 (LeakyReLU)            (None, 15, 20, 1024) 0           bnorm_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_254 (Add)                   (None, 15, 20, 1024) 0           add_253[0][0]                    \n",
            "                                                                 leaky_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_75 (Conv2D)                (None, 15, 20, 512)  524288      add_254[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_75 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_75[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_75 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_76 (Conv2D)                (None, 15, 20, 1024) 4718592     leaky_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_76 (BatchNormalization)   (None, 15, 20, 1024) 4096        conv_76[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_76 (LeakyReLU)            (None, 15, 20, 1024) 0           bnorm_76[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_77 (Conv2D)                (None, 15, 20, 512)  524288      leaky_76[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_77 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_77[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_77 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_77[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_78 (Conv2D)                (None, 15, 20, 1024) 4718592     leaky_77[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_78 (BatchNormalization)   (None, 15, 20, 1024) 4096        conv_78[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_78 (LeakyReLU)            (None, 15, 20, 1024) 0           bnorm_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_79 (Conv2D)                (None, 15, 20, 512)  524288      leaky_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_79 (BatchNormalization)   (None, 15, 20, 512)  2048        conv_79[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_79 (LeakyReLU)            (None, 15, 20, 512)  0           bnorm_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_84 (Conv2D)                (None, 15, 20, 11)   5632        leaky_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bnorm_84 (BatchNormalization)   (None, 15, 20, 11)   44          conv_84[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_84 (LeakyReLU)            (None, 15, 20, 11)   0           bnorm_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_24 (Lambda)              (None, 15, 20, 1)    0           leaky_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_26 (Lambda)              (None, 15, 20, 6)    0           leaky_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 15, 20, 1)    0           lambda_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_25 (Lambda)              (None, 15, 20, 4)    0           leaky_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 15, 20, 6)    0           lambda_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 15, 20, 11)   0           activation_16[0][0]              \n",
            "                                                                 lambda_25[0][0]                  \n",
            "                                                                 activation_17[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 51,650,700\n",
            "Trainable params: 51,607,798\n",
            "Non-trainable params: 42,902\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xALoMACG_00H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e9e9b817-65b9-4df3-d075-63e44007ad07"
      },
      "source": [
        "array = tf.constant([[1,2,-3,4, 7], [2,-3,4,-5,6]])\n",
        "mask = tf.greater(array, 0)\n",
        "print(mask)\n",
        "non_zero_array = tf.boolean_mask(array, mask)\n",
        "print(non_zero_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ True  True False  True  True]\n",
            " [ True False  True False  True]], shape=(2, 5), dtype=bool)\n",
            "tf.Tensor([1 2 4 7 2 4 6], shape=(7,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z95CuC6KdXDz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ec186e5-a347-4569-ae31-973481d80c03"
      },
      "source": [
        "yolov3 = tf.keras.models.load_model(path+'/yolov3.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFBn86xcwoVi"
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "  prob_of_object_true = y_true[:,:,:,0:1]\n",
        "  prob_of_object_pred = y_pred[:,:,:,0:1]\n",
        "  pred_loss = tf.keras.losses.BinaryCrossentropy()(prob_of_object_true, prob_of_object_pred)\n",
        "  '''\n",
        "  selected_pred = tf.math.multiply(prob_of_object_true, y_pred)\n",
        "  \n",
        "  selected_pred_coord = selected_pred[:,:,:,1:5]\n",
        "  mse_loss = keras.losses.mse(selected_pred_coord, y_true[:,:,:,1:5])\n",
        " \n",
        "  selected_pred_classes = selected_pred[:,:,:,5:]\n",
        "  categorical_loss = keras.losses.categorical_crossentropy(y_true[:,:,:,5:], selected_pred_classes)\n",
        "  '''\n",
        "  \n",
        "  true = tf.where(y_true[0, :, :, 0] > 0).numpy()\n",
        "  start0 = true[0][0]\n",
        "  start1 = true[0][1]\n",
        " \n",
        "  end0 = true[-1][0]\n",
        "  end1 = true[-1][1]\n",
        " \n",
        "  coord_pred = tf.slice(y_pred, (0, start0, start1,1), (1, end0-start0+1, end1-start1+1, 4))\n",
        "  coord_true = tf.slice(y_true, (0, start0, start1,1), (1, end0-start0+1, end1-start1+1, 4))\n",
        "  \n",
        "  coord_loss =  tf.keras.losses.MeanSquaredError()(coord_true, coord_pred)\n",
        " \n",
        "  classes_pred = tf.slice(y_pred, (0, start0, start1,5), (1, end0-start0+1, end1-start1+1, 6))\n",
        "  classes_true = tf.slice(y_true, (0, start0, start1,5), (1, end0-start0+1, end1-start1+1, 6))\n",
        "  \n",
        "  classes_loss = tf.keras.losses.CategoricalCrossentropy()(classes_true, classes_pred)\n",
        " \n",
        "  assert (tf.shape(coord_loss).numpy() == tf.shape(classes_loss).numpy()).all() \n",
        "  #assert (tf.shape(coord_loss).numpy() == tf.shape(pred_loss).numpy()).all()\n",
        "  \n",
        "  #print(pred_loss, coord_loss, classes_loss)\n",
        " \n",
        "  loss = pred_loss + coord_loss/100 + 2*classes_loss\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCWvVZ6YGY2i"
      },
      "source": [
        "def loss_fn_d(y_true, y_pred):\n",
        "  return tf.reduce_mean(0*y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iuHMTFQrxoF"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.000001)\n",
        "a = tf.constant(1, dtype = tf.float64)\n",
        "dummy_x = tf.constant(np.zeros((1, 120, 160, 3)), dtype = tf.float32)\n",
        "no_iter = 1000\n",
        "for i in range(no_iter):\n",
        "    with tf.GradientTape() as Tape:\n",
        "        dummy_y = yolov3(dummy_x)\n",
        "        loss = loss_fn_d(dummy_y, dummy_y)\n",
        "    grad_total = Tape.gradient(loss, yolov3.trainable_variables)\n",
        "    loss = 0\n",
        " \n",
        "    for exp in range(xTrain.shape[0]):\n",
        "        inp  = xTrain[exp]\n",
        "        inp = np.expand_dims(inp, axis = 0)\n",
        "        y_true = yTrain[exp]\n",
        "        y_true = np.expand_dims(y_true, axis = 0)\n",
        "        with tf.GradientTape() as Tape:\n",
        "          y_pred = yolov3(inp)\n",
        "          loss_temp = custom_loss(y_true, y_pred)\n",
        "          loss+=loss_temp\n",
        "        grad = Tape.gradient(loss_temp, yolov3.trainable_variables)\n",
        "        #print(grad[0])\n",
        "        for l in range(len(grad)):\n",
        "           grad_total[l] += grad[l]\n",
        "    print(i, loss)  \n",
        "    optimizer.apply_gradients(zip(grad_total, yolov3.trainable_variables))\n",
        "    yolov3.save(path+'/yolov3.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic1QEs_ANuQp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcptYPz1H_rI"
      },
      "source": [
        "\n",
        "imge = xTest[8:9, :, :, :]\n",
        "np.copyto(imge, xTest[10:11, :, :, :])\n",
        "cv2_imshow(imge[0])\n",
        "\n",
        "pred = yolov3(imge)\n",
        "pred = pred[0,:,:,:].numpy()\n",
        "img = imge[0]\n",
        "ref = 0.5\n",
        "\n",
        "for i in range(pred.shape[0]):\n",
        "  for j in range(pred.shape[1]):\n",
        "    conf = pred[i,j,0]\n",
        "    if conf <= 0.99 :\n",
        "      pass\n",
        "    else:\n",
        "      idx = np.argmax(pred[i,j,5:]) \n",
        "      \n",
        "      name = dct_rev[idx]\n",
        "      \n",
        "      \n",
        "      if pred[i,j,idx+5] > 0.99:\n",
        "        print(idx)\n",
        "        img = cv2.rectangle(img, (int(pred[i,j,1]), int(pred[i,j,2])), (int(pred[i,j,1] + pred[i,j,3]), int(pred[i,j,2] + pred[i,j,4])),  (0,255,0), 1)\n",
        "cv2_imshow(img)        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMk6CtkjcfED"
      },
      "source": [
        "### try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrflsEgzbW6G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}